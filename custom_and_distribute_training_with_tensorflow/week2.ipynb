{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108acb2b-0b59-4a34-bcba-fd67cfb107e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfdsk\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.ticker as mticker\n",
    "import math\n",
    "\n",
    "print( tf.__version__)\n",
    "mnist = keras.datasets.fashion_mnist \n",
    "(train_data, train_labels), (test_data, test_labels )=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d427288-97d8-4b7b-8a5a-567ab5ab7437",
   "metadata": {},
   "source": [
    "mnist = keras.datasets.fashion_mnist\n",
    "(train_data, train_labels), (test_data, test_labels )=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c555dbd5-db00-4564-a64f-acbd58992778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#train_data = train_data/255.0\n",
    "#test_data = test_data/255.0\n",
    "\n",
    "ele_1 = train_data[0]\n",
    "ele_1 = ele_1.reshape(-1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b411ee-850b-4f60-8fa8-2fb1f06c0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_image( data ):\n",
    "    image = data.reshape(-1)\n",
    "    image = image/255.0\n",
    "    return image\n",
    "\n",
    "train_data =np.array(list(map( format_image, train_data)))\n",
    "test_data = np.array(list(map(format_image, test_data)))\n",
    "(size, t1) = train_data.shape\n",
    "batch_num = math.ceil(size/64)\n",
    "\n",
    "(test_batchsize, t2 ) = test_data.shape\n",
    "testbatch_num = math.ceil(test_batchsize/64)\n",
    "train_data = np.array_split( train_data, batch_num)\n",
    "train_labels = np.array_split( train_labels, batch_num)\n",
    "\n",
    "test_data = np.array_split( test_data, testbatch_num)\n",
    "test_labels = np.array_split( test_labels, testbatch_num)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0382802c-47f7-43ae-bd99-1cd0a17ff20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "    inputs = Input( shape = (784, ), name = 'digits')\n",
    "    #x = Flatten( )(inputs)\n",
    "    x = Dense(128, activation = 'relu', name='dense_1')(inputs)\n",
    "    x = Dense( 128, activation = 'relu', name='dense_2')(x)\n",
    "    outputs = Dense( 10, activation = 'softmax', name='prediction')(x)\n",
    "    model = Model( inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d182f0-a9a7-4927-b34e-89022724d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient( optimizer, model, x, y ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss_value = loss_object( y_true = y, y_pred= logits)\n",
    "    gradients = tape.gradient( loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    return logits, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "011539e7-c0ac-446c-84fa-de5915f6005f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(64, 784)\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.summary()\n",
    "print( train_data[0].shape)\n",
    "#print( model(train_data[0]))\n",
    "def train_data_for_one_epoch():\n",
    "    losses = [];\n",
    "    step = 0\n",
    "    pbar = tqdm(total=len(train_data), position = 0, leave = True, bar_format='{l_bar}{bar}|{n_fmt}/{total_fmt}')\n",
    "    for x_batch_train, y_batch_train in zip(train_data, train_labels):\n",
    "        logits,loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\n",
    "        losses.append( loss_value)\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "        step = step + 1\n",
    "    pbar.set_description( \"Training loss for step %s: %.4f\" %(int(step), float(loss_value)))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d232be-1ee8-499b-97c8-ef15a79b6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "    losses = []\n",
    "    for x_val, y_val in zip(test_data, test_labels):\n",
    "        val_logits = model(x_val)\n",
    "        val_loss = loss_object(y_true = y_val, y_pred = val_logits)\n",
    "        losses.append(val_loss)\n",
    "        val_acc_metric(y_val, val_logits)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6959ed28-302a-482f-bd66-41dddfb5f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.3265:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0: Train loss: 0.3695 Validation Loss: 0.4091, Train Accuracy: 0.8427, Validation Accuracy 0.8502\n",
      "start of epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2785:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1: Train loss: 0.3303 Validation Loss: 0.3861, Train Accuracy: 0.8552, Validation Accuracy 0.8546\n",
      "start of epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2785:   0%|          |0/938\n",
      "Training loss for step 938: 0.2679:   0%|          |0/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 2: Train loss: 0.3056 Validation Loss: 0.3740, Train Accuracy: 0.8630, Validation Accuracy 0.8573\n",
      "start of epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2627:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 3: Train loss: 0.2879 Validation Loss: 0.3728, Train Accuracy: 0.8691, Validation Accuracy 0.8590\n",
      "start of epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2499:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 4: Train loss: 0.2719 Validation Loss: 0.3753, Train Accuracy: 0.8739, Validation Accuracy 0.8604\n",
      "start of epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2627:   0%|          |0/938\n",
      "Training loss for step 938: 0.2499:   0%|          |0/938\n",
      "Training loss for step 938: 0.2301:   0%|          |0/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 5: Train loss: 0.2573 Validation Loss: 0.3651, Train Accuracy: 0.8783, Validation Accuracy 0.8620\n",
      "start of epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2317:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 6: Train loss: 0.2465 Validation Loss: 0.3408, Train Accuracy: 0.8820, Validation Accuracy 0.8642\n",
      "start of epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2336:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 7: Train loss: 0.2358 Validation Loss: 0.3588, Train Accuracy: 0.8852, Validation Accuracy 0.8654\n",
      "start of epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.2317:   0%|          |0/938\n",
      "Training loss for step 938: 0.2336:   0%|          |0/938\n",
      "Training loss for step 938: 0.1818:   0%|          |0/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 8: Train loss: 0.2242 Validation Loss: 0.3615, Train Accuracy: 0.8883, Validation Accuracy 0.8666\n",
      "start of epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.1699:   0%|          |0/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 9: Train loss: 0.2145 Validation Loss: 0.3600, Train Accuracy: 0.8911, Validation Accuracy 0.8678\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "epochs_val_losses, epochs_train_losses = [],[]\n",
    "\n",
    "for epoch in range( epochs ):\n",
    "    print( 'start of epoch %d' % (epoch,))\n",
    "    losses_train = train_data_for_one_epoch()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    \n",
    "    losses_val = perform_validation()\n",
    "    val_acc = val_acc_metric.result()\n",
    "    \n",
    "    losses_train_mean = np.mean( losses_train)\n",
    "    losses_val_mean = np.mean( losses_val )\n",
    "    epochs_val_losses.append( losses_val_mean)\n",
    "    epochs_train_losses.append( losses_train_mean )\n",
    "    \n",
    "    print( '\\n Epoch %s: Train loss: %.4f Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' \n",
    "          %(epoch, float(losses_train_mean), float( losses_val_mean), float(train_acc), float(val_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ce56f-096a-4be5-b775-fd9a52572294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training loss for step 938: 0.1699:   0%|          |0/938\n"
     ]
    }
   ],
   "source": [
    "def plot_metrics( train_metric, val_metric, metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0, ylim)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    plt.plot( train_metric, color = 'blue', label = metric_name)\n",
    "    plt.plot( val_metric, color = 'green', label = 'val_' + metric_name)\n",
    "    plt.show()\n",
    "    \n",
    "plot_metrics( epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c923237-4a19-4119-8e62-05647291f66c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c903684e-5745-43b5-8ce0-da870f5cc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from configs import ParseParams\n",
    "from DataGenerator import DataGenerator\n",
    "from env import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4043f8e3-9675-4543-a895-80f55438fec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionVRPCritic(object):\n",
    "    \"\"\"A generic attention module for the attention in vrp model\"\"\"\n",
    "    def __init__(self, dim, use_tanh=False, C=10,_name='Attention',_scope=''):\n",
    "\n",
    "        self.use_tanh = use_tanh\n",
    "        self._scope = _scope\n",
    "\n",
    "        with tf.compat.v1.variable_scope(_scope+_name):\n",
    "            # self.v: is a variable with shape [1 x dim]\n",
    "            self.v = tf.compat.v1.get_variable('v',[1,dim],\n",
    "                       initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "            self.v = tf.expand_dims(self.v,2)\n",
    "            \n",
    "        self.emb_d = tf.compat.v1.layers.Conv1D(dim,1,_scope=_scope+_name +'/emb_d') #conv1d\n",
    "        self.project_d = tf.compat.v1.layers.Conv1D(dim,1,_scope=_scope+_name +'/proj_d') #conv1d_1\n",
    "        \n",
    "        self.project_query = tf.compat.v1.layers.Dense(dim,_scope=_scope+_name +'/proj_q') #\n",
    "        self.project_ref = tf.compat.v1.layers.Conv1D(dim,1,_scope=_scope+_name +'/proj_e') #conv1d_2\n",
    "\n",
    "        self.C = C  # tanh exploration parameter\n",
    "        self.tanh = tf.nn.tanh\n",
    "        \n",
    "    def __call__(self, query, ref, env):\n",
    "        \"\"\"\n",
    "        This function gets a query tensor and ref rensor and returns the logit op.\n",
    "        Args: \n",
    "            query: is the hidden state of the decoder at the current\n",
    "                time step. [batch_size x dim]\n",
    "            ref: the set of hidden states from the encoder. \n",
    "                [batch_size x max_time x dim]\n",
    "\n",
    "            env: keeps demand ond load values and help decoding. Also it includes mask.\n",
    "                env.mask: a matrix used for masking the logits and glimpses. It is with shape\n",
    "                         [batch_size x max_time]. Zeros in this matrix means not-masked nodes. Any \n",
    "                         positive number in this mask means that the node cannot be selected as next \n",
    "                         decision point.\n",
    "                env.demands: a list of demands which changes over time.\n",
    "\n",
    "        Returns:\n",
    "            e: convolved ref with shape [batch_size x max_time x dim]\n",
    "            logits: [batch_size x max_time]\n",
    "        \"\"\"\n",
    "        # we need the first demand value for the critic\n",
    "        demand = env.input_data[:,:,-1]\n",
    "        max_time = tf.shape(input=demand)[1]\n",
    "\n",
    "        # embed demand and project it\n",
    "        # emb_d:[batch_size x max_time x dim ]\n",
    "        emb_d = self.emb_d(tf.expand_dims(demand,2))\n",
    "        # d:[batch_size x max_time x dim ]\n",
    "        d = self.project_d(emb_d)\n",
    "\n",
    "\n",
    "        # expanded_q,e: [batch_size x max_time x dim]\n",
    "        e = self.project_ref(ref)\n",
    "        q = self.project_query(query) #[batch_size x dim]\n",
    "        expanded_q = tf.tile(tf.expand_dims(q,1),[1,max_time,1])\n",
    "\n",
    "        # v_view:[batch_size x dim x 1]\n",
    "        v_view = tf.tile( self.v, [tf.shape(input=e)[0],1,1]) \n",
    "        \n",
    "        # u : [batch_size x max_time x dim] * [batch_size x dim x 1] = \n",
    "        #       [batch_size x max_time]\n",
    "        u = tf.squeeze(tf.matmul(self.tanh(expanded_q + e + d), v_view),2)\n",
    "\n",
    "        if self.use_tanh:\n",
    "            logits = self.C * self.tanh(u)\n",
    "        else:\n",
    "            logits = u  \n",
    "\n",
    "        return e, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9511658f-3716-46bb-8667-056b90cac162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train iterator.\n",
      "Loading dataset for vrp-size-1000-len-5-test.txt...\n"
     ]
    }
   ],
   "source": [
    "#tf.compat.v1.disable_eager_execution()\n",
    "args, prt = ParseParams()\n",
    "batch_size = 2\n",
    "nodes = 5\n",
    "cust = nodes-1\n",
    "args['batch_size'] = batch_size\n",
    "args['n_nodes'] = nodes\n",
    "args['n_cust'] = cust\n",
    "env = Env( args)\n",
    "\n",
    "node_num = args['n_nodes']\n",
    "emb_dim = 30\n",
    "lstm_dim = args['hidden_dim']\n",
    "batch_num = 2\n",
    "process = AttentionVRPCritic( lstm_dim, \"P\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ae8e82-ced6-4425-a40d-7d975093e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.419918  8.952817  9.180444  7.7896266 7.4645944]\n",
      " [8.766563  9.583124  9.295224  9.779091  8.14705  ]]\n",
      "[[-1.0120552 -1.4791563 -1.2515295 -2.6423466 -2.9673789]\n",
      " [-2.1102276 -1.2936668 -1.5815668 -1.0977001 -2.729741 ]]\n",
      "[[0.3634712  0.22782984 0.28606695 0.07119401 0.05143796]\n",
      " [0.12121038 0.27426326 0.20565262 0.33363754 0.06523618]]\n",
      "[[0]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "ref = tf.cast( np.random.randn( batch_num, node_num, emb_dim), tf.float32 )\n",
    "query = tf.cast( np.random.randn(batch_num, lstm_dim ), tf.float32 )\n",
    "\n",
    "o1, logits = process( query, ref, env )\n",
    "print( logits.numpy())\n",
    "logprob = tf.nn.log_softmax(logits)\n",
    "print( logprob.numpy())\n",
    "prob = tf.exp(logprob)\n",
    "print(prob.numpy())\n",
    "idx = tf.expand_dims(tf.argmax(input=prob, axis=1),1)\n",
    "print( idx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e251d1cd-d1c9-4717-89ed-f150fd0196db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

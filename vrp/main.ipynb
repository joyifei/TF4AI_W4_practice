{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faea458-a17d-44c8-a021-c32fd644a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import shared.misc_utils as utils\n",
    "\n",
    "from configs import ParseParams\n",
    "\n",
    "#from shared import embeddings\n",
    "\n",
    "from evaluation.benchmark import benchmark\n",
    "from model.attention_agent import RLAgent\n",
    "\n",
    "import pickle,time,os\n",
    "\n",
    "from configs import ParseParams\n",
    "from shared.graph_embedding.useful_files.gnn_film_model import GNN_FiLM_Model\n",
    "from shared.graph_embedding.useful_files.number_vehicle_task import Nb_Vehicles_Task\n",
    "from VRP.vrp_utils import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f80b4a2-0a02-4100-8668-f8fff97d4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(object):\n",
    "    '''\n",
    "    This class is the base class for embedding the input graph.\n",
    "    '''\n",
    "    def __init__(self,emb_type, embedding_dim):\n",
    "        self.emb_type = emb_type\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.total_time = 0\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # returns the embeded tensor. Should be implemented in child classes\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f88e4e0-e566-4608-9183-7e40dfc8f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEmbedding(Embedding):\n",
    "    '''\n",
    "    This class implements linear embedding. It is only a mapping \n",
    "    to a higher dimensional space.\n",
    "    '''\n",
    "    def __init__(self,embedding_dim,_scope=''):\n",
    "        '''\n",
    "        Input: \n",
    "            embedding_dim: embedding dimension\n",
    "        '''\n",
    "\n",
    "        super(LinearEmbedding,self).__init__('linear',embedding_dim)\n",
    "        self.project_emb = tf.compat.v1.layers.Conv1D(embedding_dim,1,\n",
    "            _scope=_scope+'Embedding/conv1d')\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # emb_inp_pnt: [batch_size, max_time, embedding_dim]\n",
    "        time_init = time.time()\n",
    "        emb_inp_pnt = self.project_emb(input_pnt)\n",
    "        # emb_inp_pnt = tf.Print(emb_inp_pnt,[emb_inp_pnt])\n",
    "        self.total_time += time.time() - time_init\n",
    "        return emb_inp_pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b03e45c-0871-4e1e-8ef2-2b184d22540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(Embedding):\n",
    "    \"\"\"\n",
    "    This class implement a graph embedding. The specificity is that it has already been optimized on\n",
    "    another task. Implementation of transfer learning.\n",
    "    \"\"\"\n",
    "    def __init__(self,args,data_test):\n",
    "        assert args['embedding_dim'] == 30, args['embedding_dim']\n",
    "        super(GraphEmbedding, self).__init__('graph',embedding_dim=args['embedding_dim'])\n",
    "\n",
    "        self.n_nodes = args['n_nodes']\n",
    "        self.embedding_dim =  args['embedding_dim']\n",
    "        model_path = 'shared/graph_embedding/model_storage/' + args['task'] + '_model.pickle'\n",
    "        result_dir = args['log_dir'] + '/embedding/'\n",
    "        os.makedirs(result_dir)\n",
    "        self.graph_model = self.restore(model_path, result_dir)\n",
    "        self.graph_model.params['max_nodes_in_batch'] = args['test_size'] * self.n_nodes + 10 # We can process larger batches if we don't do training\n",
    "        self.embedded_data = self(data_test)\n",
    "\n",
    "\n",
    "    def __call__(self, input_data):\n",
    "        \"\"\"\n",
    "        :param input_data: the input data as given by the env i.e. [batch_size x max_time x dim_task]\n",
    "        :return: an embedding corresponding to the final node represenatation obtained via transfer learning.\n",
    "        \"\"\"\n",
    "        time_init = time.time()\n",
    "        embedded_data = self.graph_model.test(input_data)\n",
    "        embedded_data = np.reshape(embedded_data,(-1,self.n_nodes,self.embedding_dim))\n",
    "        self.total_time += time.time() - time_init\n",
    "\n",
    "        return embedded_data\n",
    "\n",
    "    @staticmethod\n",
    "    def restore(saved_model_path: str, result_dir: str, run_id: str = None):\n",
    "        print(\"Loading model from file %s.\" % saved_model_path)\n",
    "        with open(saved_model_path, 'rb') as in_file:\n",
    "            data_to_load = pickle.load(in_file)\n",
    "\n",
    "        # model_cls, _ = name_to_model_class(data_to_load['model_class']({}))   # before...\n",
    "        model_cls = GNN_FiLM_Model\n",
    "        task_cls, additional_task_params = Nb_Vehicles_Task, {\"data_kind\":'transfer_learning'}\n",
    "\n",
    "        if run_id is None:\n",
    "            run_id = \"_\".join([task_cls.name(), model_cls.name(data_to_load['model_params']), time.strftime(\"%Y-%m-%d-%H-%M-%S\"), str(os.getpid())])\n",
    "\n",
    "        task = task_cls(data_to_load['task_params'])\n",
    "        task.restore_from_metadata(data_to_load['task_metadata'])\n",
    "\n",
    "        model = model_cls(data_to_load['model_params'], task, run_id, result_dir)\n",
    "        model.load_weights(data_to_load['weights'])\n",
    "\n",
    "        model.log_line(\"Loaded model from snapshot %s.\" % saved_model_path)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df6edbd-ed07-46f2-806f-11acb4b7e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    args, prt = ParseParams()\n",
    "    data_Gen = DataGenerator(args)\n",
    "    # print(data_Gen.test_data)\n",
    "    print(data_Gen.test_data.shape)\n",
    "\n",
    "    graph_embedding = GraphEmbedding(args,data_Gen.test_data)\n",
    "    data = data_Gen.get_train_next()\n",
    "    graph_embedding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0df5d3-0a5b-48d3-8596-03eab37f7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor_net_lr: 0.0001\n",
      "agent_type: attention\n",
      "batch_size: 128\n",
      "beam_width: 5\n",
      "capacity: 20\n",
      "critic_net_lr: 0.0001\n",
      "data_dir: ./data\n",
      "decode_len: 20\n",
      "demand_max: 9\n",
      "disable_tqdm: True\n",
      "dropout: 0.1\n",
      "embedding_dim: 30\n",
      "embedding_graph: 2\n",
      "entropy_coeff: 0.0\n",
      "forget_bias: 1.0\n",
      "gpu: 3\n",
      "hidden_dim: 128\n",
      "infer_type: batch\n",
      "input_dim: 3\n",
      "is_train: True\n",
      "load_path: \n",
      "log_dir: logs/vrp10-2021-05-03_18-07-48\n",
      "log_interval: 200\n",
      "mask_glimpses: True\n",
      "mask_pointer: True\n",
      "max_grad_norm: 2.0\n",
      "min_trucks: False\n",
      "model_dir: logs/vrp10-2021-05-03_18-07-48\\model\n",
      "n_cust: 10\n",
      "n_glimpses: 0\n",
      "n_nodes: 11\n",
      "n_process_blocks: 3\n",
      "n_train: 260000\n",
      "random_seed: 24601\n",
      "rnn_layers: 1\n",
      "save_interval: 1000\n",
      "stdout_print: True\n",
      "tanh_exploration: 10.0\n",
      "task: vrp10\n",
      "task_name: vrp\n",
      "test_interval: 200\n",
      "test_size: 1000\n",
      "ups: False\n",
      "use_tanh: False\n",
      "Created train iterator.\n",
      "Loading dataset for vrp-size-1000-len-11-test.txt...\n",
      "(1000, 11, 3)\n",
      "Loading model from file shared/graph_embedding/model_storage/vrp10_model.pickle.\n",
      "Model has 116910 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\vrp\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta/Adam_1:0 since no saved value was found.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Loaded model from snapshot shared/graph_embedding/model_storage/vrp10_model.pickle.\n",
      "== Running Test on ==\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/vrp-size-5000-len-11-results-or_tools.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;34mE:\\anaconda\\envs\\vrp\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m, in \u001b[0;32mrun_code\u001b[0m:\nLine \u001b[0;34m3437\u001b[0m:  exec(code_obj, \u001b[36mself\u001b[39;49;00m.user_global_ns, \u001b[36mself\u001b[39;49;00m.user_ns)\n",
      "In  \u001b[0;34m[6]\u001b[0m:\nLine \u001b[0;34m168\u001b[0m:   test()\n",
      "In  \u001b[0;34m[5]\u001b[0m:\nLine \u001b[0;34m7\u001b[0m:     graph_embedding = GraphEmbedding(args,data_Gen.test_data)\n",
      "In  \u001b[0;34m[4]\u001b[0m:\nLine \u001b[0;34m17\u001b[0m:    \u001b[36mself\u001b[39;49;00m.embedded_data = \u001b[36mself\u001b[39;49;00m(data_test)\n",
      "In  \u001b[0;34m[4]\u001b[0m:\nLine \u001b[0;34m26\u001b[0m:    embedded_data = \u001b[36mself\u001b[39;49;00m.graph_model.test(input_data)\n",
      "File \u001b[0;34mE:\\GitHub\\TF4AI_practice\\vrp\\shared\\graph_embedding\\useful_files\\sparse_graph_model.py\u001b[0m, in \u001b[0;32mtest\u001b[0m:\nLine \u001b[0;34m392\u001b[0m:   data = \u001b[36mself\u001b[39;49;00m.task.load_eval_data_from_path(path=\u001b[33m'\u001b[39;49;00m\u001b[33mdata/vrp-size-5000-len-11-results-or_tools.txt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "File \u001b[0;34mE:\\GitHub\\TF4AI_practice\\vrp\\shared\\graph_embedding\\useful_files\\number_vehicle_task.py\u001b[0m, in \u001b[0;32mload_eval_data_from_path\u001b[0m:\nLine \u001b[0;34m103\u001b[0m:   dist_matrix,type_num, features, labels = helper_loader.fast_load_data_path(path)\n",
      "File \u001b[0;34mE:\\GitHub\\TF4AI_practice\\vrp\\shared\\graph_embedding\\transfer_learning_dataset_utils.py\u001b[0m, in \u001b[0;32mfast_load_data_path\u001b[0m:\nLine \u001b[0;34m53\u001b[0m:    list_label, input_path = \u001b[36mself\u001b[39;49;00m._parse_txt_input_to_array(path)\n",
      "File \u001b[0;34mE:\\GitHub\\TF4AI_practice\\vrp\\shared\\graph_embedding\\transfer_learning_dataset_utils.py\u001b[0m, in \u001b[0;32m_parse_txt_input_to_array\u001b[0m:\nLine \u001b[0;34m199\u001b[0m:   nb_line = TransferDatasetUtils.file_len(path)\n",
      "File \u001b[0;34mE:\\GitHub\\TF4AI_practice\\vrp\\shared\\graph_embedding\\transfer_learning_dataset_utils.py\u001b[0m, in \u001b[0;32mfile_len\u001b[0m:\nLine \u001b[0;34m247\u001b[0m:   \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(fname) \u001b[34mas\u001b[39;49;00m f:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/vrp-size-5000-len-11-results-or_tools.txt'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "    \n",
    "def load_task_specific_components(task,ups):\n",
    "    '''\n",
    "    This function load task-specific libraries\n",
    "    '''\n",
    "    if task == 'vrp':\n",
    "        if ups:\n",
    "            from UPS.vrp_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrp_ups_attention import AttentionVRP_UPS_Actor, AttentionVRP_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRP_UPS_Actor\n",
    "            AttentionCritic = AttentionVRP_UPS_Critic\n",
    "\n",
    "        else:\n",
    "            from VRP.vrp_utils import DataGenerator,Env,reward_func\n",
    "            from VRP.vrp_attention import AttentionVRPActor,AttentionVRPCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPActor\n",
    "            AttentionCritic = AttentionVRPCritic\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        if ups:\n",
    "            from UPS.vrptw_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrptw_ups_attention import AttentionVRPTW_UPS_Actor, AttentionVRPTW_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRPTW_UPS_Actor\n",
    "            AttentionCritic = AttentionVRPTW_UPS_Critic\n",
    "        else:\n",
    "            from VRPTW.vrptw_utils import DataGenerator,Env,reward_func\n",
    "            from VRPTW.vrptw_attention import AttentionVRPTWActor, AttentionVRPTWCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPTWActor\n",
    "            AttentionCritic = AttentionVRPTWCritic\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')\n",
    "\n",
    "    return DataGenerator, Env, reward_func, AttentionActor, AttentionCritic\n",
    "\n",
    "\n",
    "def load_task_specific_eval(task):\n",
    "    \"\"\"\n",
    "    Load taks specific, dependign of tw or not\n",
    "    \"\"\"\n",
    "    if task == 'vrp':\n",
    "        from evaluation.eval_VRP import eval_google_or,eval_Clarke_Wright\n",
    "\n",
    "        return [(eval_google_or.EvalGoogleOR,'or_tools'), (eval_Clarke_Wright.EvalClarkeWright,'Clarke_Wright')]\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        from evaluation.eval_VRPTW import eval_tw_google_or,eval_I1_heuristics\n",
    "\n",
    "        return [(eval_tw_google_or.EvalTWGoogleOR,'or_tools_tw'),(eval_I1_heuristics.EvalI1Heuristics,'I1_heuristic')]\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')\n",
    "\n",
    "\n",
    "def main(args, prt):\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    # load task specific classes\n",
    "    DataGenerator, Env, reward_func, AttentionActor, AttentionCritic = \\\n",
    "        load_task_specific_components(args['task_name'],args['ups'])\n",
    "\n",
    "    dataGen = DataGenerator(args)\n",
    "    dataGen.reset()\n",
    "    env = Env(args)\n",
    "    # create an RL agent\n",
    "    agent = RLAgent(args,\n",
    "                    prt,\n",
    "                    env,\n",
    "                    dataGen,\n",
    "                    reward_func,\n",
    "                    AttentionActor,\n",
    "                    AttentionCritic,\n",
    "                    is_train=args['is_train'])\n",
    "    agent.Initialize(sess)\n",
    "\n",
    "    # train or evaluate\n",
    "    prev_actor_loss, prev_critic_loss = float('Inf'), float('Inf')\n",
    "    actor_eps, critic_eps = 1e-2, 1e-2\n",
    "    start_time = time.time()\n",
    "    convergence_counter = 0\n",
    "    al_file = open(args['log_dir']+\"/actorLoss.txt\", \"w\")\n",
    "    cl_file = open(args['log_dir']+\"/criticLoss.txt\", \"w\")\n",
    "    r_file = open(args['log_dir']+\"/reward.txt\", \"w\")\n",
    "\n",
    "    if args['is_train']:\n",
    "        prt.print_out('Training started ...')\n",
    "        train_time_beg = time.time()\n",
    "        for step in range(args['n_train']):\n",
    "            summary = agent.run_train_step()\n",
    "            _, _ , actor_loss_val, critic_loss_val, actor_gra_and_var_val, critic_gra_and_var_val,\\\n",
    "                R_val, v_val, logprobs_val,probs_val, actions_val, idxs_val= summary\n",
    "\n",
    "            curr_actor_loss = np.mean(actor_loss_val)\n",
    "            curr_critic_loss = np.mean(critic_loss_val)\n",
    "            al_file.write( str(actor_loss_val) + '\\n')\n",
    "            cl_file.write(str(critic_loss_val) + '\\n')\n",
    "            r_file.write(str(np.mean(R_val)) + '\\n')\n",
    "\n",
    "            if abs(prev_actor_loss - curr_actor_loss) < actor_eps \\\n",
    "                and abs(prev_critic_loss - curr_critic_loss) < critic_eps:\n",
    "                convergence_counter += 1\n",
    "            else:\n",
    "                convergence_counter = 0\n",
    "            if convergence_counter == 10:\n",
    "                prt.print_out('Converged at step {}'\\\n",
    "                      .format(step))\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss,curr_critic_loss))\n",
    "                break\n",
    "\n",
    "            if step%args['save_interval'] == 0:\n",
    "                agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "            if step%args['log_interval'] == 0:\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Embedding Time {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        agent.embedder_model.total_time)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss, curr_critic_loss))\n",
    "\n",
    "                train_time_beg = time.time()\n",
    "                agent.embedder_model.total_time = 0\n",
    "            if step%args['test_interval'] == 0:\n",
    "                agent.inference(args['infer_type'])\n",
    "            prev_actor_loss = curr_actor_loss\n",
    "            prev_critic_loss = curr_critic_loss\n",
    "\n",
    "        # Save the model at the end of the training\n",
    "        agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "    else: # inference\n",
    "        prt.print_out('Evaluation started ...')\n",
    "        agent.inference(args['infer_type'])\n",
    "\n",
    "        all_evaluator = load_task_specific_eval(args['task_name'])\n",
    "\n",
    "        # perform the evaluation\n",
    "        list_eval = ['beam_search'] #['greedy','beam_search']\n",
    "        for eval_tuple in all_evaluator:\n",
    "            list_eval.append(eval_tuple[1])\n",
    "\n",
    "            object_eval = eval_tuple[0](args,env,prt,args['min_trucks'])\n",
    "            object_eval.perform_routing()\n",
    "        #\n",
    "        benchmark_object = benchmark.Benchmark(args,env,prt)\n",
    "        # list_eval.remove('Clarke_Wright')\n",
    "        # #list_eval.remove('I1_heuristic')\n",
    "        benchmark_object.perform_benchmark(list_eval=list_eval)\n",
    "\n",
    "    prt.print_out('Total time is {}'.format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time))))\n",
    "    al_file.close()\n",
    "    cl_file.close()\n",
    "    r_file.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "    assert False\n",
    "    args, prt = ParseParams()\n",
    "    args['is_train'] = True\n",
    "    # args['infer_type'] = 'single'\n",
    "    args['test_size'] = 1000\n",
    "   #  args['log_dir'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp20-2019-12-05_09-28-11/\"\n",
    "    # args['load_path'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp50-NbTruck/model/\"\n",
    "\n",
    "    # args['data_dir'] = \"drive/My Drive/VRP-RL/data\"\n",
    "    # args['log_dir'] = \"drive/My Drive/VRP-RL/logs\"\n",
    "    # args['log_dir'] = \"{}/{}-{}\".format(args['log_dir'],args['task'], utils.get_time())\n",
    "    # print(args['log_dir'])\n",
    "    # args['model_dir'] = os.path.join(args['log_dir'],'model')\n",
    "    #\n",
    "    # args['load_path'] = \"drive/My Drive/VRP-RL/logs/vrptw50-2019-11-25_01-28-09/model/\"\n",
    "    # print(args['model_dir'])\n",
    "    # # file to write the stdout\n",
    "    # try:\n",
    "    #     os.makedirs(args['log_dir'])\n",
    "    #     os.makedirs(args['model_dir'])\n",
    "    # except:\n",
    "    #     pass\n",
    "    #\n",
    "    # # create a print handler\n",
    "    # out_file = open(os.path.join(args['log_dir'], 'results.txt'),'w+')\n",
    "    # prt = utils.printOut(out_file,args['stdout_print'])\n",
    "\n",
    "    # Random\n",
    "\n",
    "    random_seed = args['random_seed']\n",
    "    if random_seed is not None and random_seed > 0:\n",
    "        prt.print_out(\"# Set random seed to %d\" % random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        tf.set_random_seed(random_seed)\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    main(args, prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6d2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3eb12-3695-474b-a493-158d88580cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

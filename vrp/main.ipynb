{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3faea458-a17d-44c8-a021-c32fd644a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import shared.misc_utils as utils\n",
    "\n",
    "from configs import ParseParams\n",
    "\n",
    "#from shared import embeddings\n",
    "\n",
    "from evaluation.benchmark import benchmark\n",
    "from model.attention_agent import RLAgent\n",
    "\n",
    "import pickle,time,os\n",
    "\n",
    "from configs import ParseParams\n",
    "from shared.graph_embedding.useful_files.gnn_film_model import GNN_FiLM_Model\n",
    "from shared.graph_embedding.useful_files.number_vehicle_task import Nb_Vehicles_Task\n",
    "from VRP.vrp_utils import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f80b4a2-0a02-4100-8668-f8fff97d4ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(object):\n",
    "    '''\n",
    "    This class is the base class for embedding the input graph.\n",
    "    '''\n",
    "    def __init__(self,emb_type, embedding_dim):\n",
    "        self.emb_type = emb_type\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.total_time = 0\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # returns the embeded tensor. Should be implemented in child classes\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f88e4e0-e566-4608-9183-7e40dfc8f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEmbedding(Embedding):\n",
    "    '''\n",
    "    This class implements linear embedding. It is only a mapping \n",
    "    to a higher dimensional space.\n",
    "    '''\n",
    "    def __init__(self,embedding_dim,_scope=''):\n",
    "        '''\n",
    "        Input: \n",
    "            embedding_dim: embedding dimension\n",
    "        '''\n",
    "\n",
    "        super(LinearEmbedding,self).__init__('linear',embedding_dim)\n",
    "        self.project_emb = tf.compat.v1.layers.Conv1D(embedding_dim,1,\n",
    "            _scope=_scope+'Embedding/conv1d')\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # emb_inp_pnt: [batch_size, max_time, embedding_dim]\n",
    "        time_init = time.time()\n",
    "        emb_inp_pnt = self.project_emb(input_pnt)\n",
    "        # emb_inp_pnt = tf.Print(emb_inp_pnt,[emb_inp_pnt])\n",
    "        self.total_time += time.time() - time_init\n",
    "        return emb_inp_pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b03e45c-0871-4e1e-8ef2-2b184d22540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(Embedding):\n",
    "    \"\"\"\n",
    "    This class implement a graph embedding. The specificity is that it has already been optimized on\n",
    "    another task. Implementation of transfer learning.\n",
    "    \"\"\"\n",
    "    def __init__(self,args,data_test):\n",
    "        assert args['embedding_dim'] == 30, args['embedding_dim']\n",
    "        super(GraphEmbedding, self).__init__('graph',embedding_dim=args['embedding_dim'])\n",
    "\n",
    "        self.n_nodes = args['n_nodes']\n",
    "        self.embedding_dim =  args['embedding_dim']\n",
    "        model_path = 'shared/graph_embedding/model_storage/' + args['task'] + '_model.pickle'\n",
    "        result_dir = args['log_dir'] + '/embedding/'\n",
    "        os.makedirs(result_dir)\n",
    "        self.graph_model = self.restore(model_path, result_dir)\n",
    "        self.graph_model.params['max_nodes_in_batch'] = args['test_size'] * self.n_nodes + 10 # We can process larger batches if we don't do training\n",
    "        self.embedded_data = self(data_test)\n",
    "\n",
    "\n",
    "    def __call__(self, input_data):\n",
    "        \"\"\"\n",
    "        :param input_data: the input data as given by the env i.e. [batch_size x max_time x dim_task]\n",
    "        :return: an embedding corresponding to the final node represenatation obtained via transfer learning.\n",
    "        \"\"\"\n",
    "        time_init = time.time()\n",
    "        embedded_data = self.graph_model.test(input_data)\n",
    "        embedded_data = np.reshape(embedded_data,(-1,self.n_nodes,self.embedding_dim))\n",
    "        self.total_time += time.time() - time_init\n",
    "\n",
    "        return embedded_data\n",
    "\n",
    "    @staticmethod\n",
    "    def restore(saved_model_path: str, result_dir: str, run_id: str = None):\n",
    "        print(\"Loading model from file %s.\" % saved_model_path)\n",
    "        with open(saved_model_path, 'rb') as in_file:\n",
    "            data_to_load = pickle.load(in_file)\n",
    "\n",
    "        # model_cls, _ = name_to_model_class(data_to_load['model_class']({}))   # before...\n",
    "        model_cls = GNN_FiLM_Model\n",
    "        task_cls, additional_task_params = Nb_Vehicles_Task, {\"data_kind\":'transfer_learning'}\n",
    "\n",
    "        if run_id is None:\n",
    "            run_id = \"_\".join([task_cls.name(), model_cls.name(data_to_load['model_params']), time.strftime(\"%Y-%m-%d-%H-%M-%S\"), str(os.getpid())])\n",
    "\n",
    "        task = task_cls(data_to_load['task_params'])\n",
    "        task.restore_from_metadata(data_to_load['task_metadata'])\n",
    "\n",
    "        model = model_cls(data_to_load['model_params'], task, run_id, result_dir)\n",
    "        model.load_weights(data_to_load['weights'])\n",
    "\n",
    "        model.log_line(\"Loaded model from snapshot %s.\" % saved_model_path)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df6edbd-ed07-46f2-806f-11acb4b7e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    args, prt = ParseParams()\n",
    "    data_Gen = DataGenerator(args)\n",
    "    # print(data_Gen.test_data)\n",
    "    print(data_Gen.test_data.shape)\n",
    "\n",
    "    graph_embedding = GraphEmbedding(args,data_Gen.test_data)\n",
    "    data = data_Gen.get_train_next()\n",
    "    graph_embedding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0df5d3-0a5b-48d3-8596-03eab37f7c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor_net_lr: 0.0001\n",
      "agent_type: attention\n",
      "batch_size: 128\n",
      "beam_width: 5\n",
      "capacity: 20\n",
      "critic_net_lr: 0.0001\n",
      "data_dir: ./data\n",
      "decode_len: 20\n",
      "demand_max: 9\n",
      "disable_tqdm: True\n",
      "dropout: 0.1\n",
      "embedding_dim: 30\n",
      "embedding_graph: 2\n",
      "entropy_coeff: 0.0\n",
      "forget_bias: 1.0\n",
      "gpu: 3\n",
      "hidden_dim: 128\n",
      "infer_type: batch\n",
      "input_dim: 3\n",
      "is_train: True\n",
      "load_path: \n",
      "log_dir: logs/vrp10-2021-05-10_12-42-31\n",
      "log_interval: 200\n",
      "mask_glimpses: True\n",
      "mask_pointer: True\n",
      "max_grad_norm: 2.0\n",
      "min_trucks: False\n",
      "model_dir: logs/vrp10-2021-05-10_12-42-31\\model\n",
      "n_cust: 10\n",
      "n_glimpses: 0\n",
      "n_nodes: 11\n",
      "n_process_blocks: 3\n",
      "n_train: 260000\n",
      "random_seed: 24601\n",
      "rnn_layers: 1\n",
      "save_interval: 1000\n",
      "stdout_print: True\n",
      "tanh_exploration: 10.0\n",
      "task: vrp10\n",
      "task_name: vrp\n",
      "test_interval: 200\n",
      "test_size: 1000\n",
      "ups: False\n",
      "use_tanh: False\n",
      "Created train iterator.\n",
      "Loading dataset for vrp-size-1000-len-11-test.txt...\n",
      "(1000, 11, 3)\n",
      "Loading model from file shared/graph_embedding/model_storage/vrp10_model.pickle.\n",
      "Model has 116910 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\vrp\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_1/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_0/layer_normalization_2/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_3/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_4/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_1/layer_normalization_5/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_6/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_7/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_2/layer_normalization_8/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_9/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_10/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_3/layer_normalization_11/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_12/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_13/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_4/layer_normalization_14/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_15/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_16/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_5/layer_normalization_17/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_18/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_19/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_6/layer_normalization_20/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_21/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_22/beta/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/gamma/Adam_1:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta/Adam:0 since no saved value was found.\n",
      "Freshly initializing graph_model/gnn_layer_7/layer_normalization_23/beta/Adam_1:0 since no saved value was found.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_0/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_1/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_2/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_3/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_4/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_5/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_6/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_1/gamma/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/beta/Adam_1:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma/Adam:0 not used by model.\n",
      "Saved weights for graph_model/gnn_layer_7/LayerNorm_2/gamma/Adam_1:0 not used by model.\n",
      "Loaded model from snapshot shared/graph_embedding/model_storage/vrp10_model.pickle.\n",
      "== Running Test on ==\n",
      "Loss 100.41397 on 1000 graphs00 graphs). Loss so far: 100.4140\n",
      "Metrics: Acc: 0.00%\n",
      "Test performed in 1.615403175354004\n",
      "== Running Test on ==\n",
      "Loss 99.16345 on 128 graphs128 graphs). Loss so far: 99.1635\n",
      "Metrics: Acc: 0.00%\n",
      "Test performed in 0.0857701301574707\n",
      "actor_net_lr: 0.0001\n",
      "agent_type: attention\n",
      "batch_size: 128\n",
      "beam_width: 5\n",
      "capacity: 20\n",
      "critic_net_lr: 0.0001\n",
      "data_dir: ./data\n",
      "decode_len: 20\n",
      "demand_max: 9\n",
      "disable_tqdm: True\n",
      "dropout: 0.1\n",
      "embedding_dim: 30\n",
      "embedding_graph: 2\n",
      "entropy_coeff: 0.0\n",
      "forget_bias: 1.0\n",
      "gpu: 3\n",
      "hidden_dim: 128\n",
      "infer_type: batch\n",
      "input_dim: 3\n",
      "is_train: True\n",
      "load_path: \n",
      "log_dir: logs/vrp10-2021-05-10_12-42-47\n",
      "log_interval: 200\n",
      "mask_glimpses: True\n",
      "mask_pointer: True\n",
      "max_grad_norm: 2.0\n",
      "min_trucks: False\n",
      "model_dir: logs/vrp10-2021-05-10_12-42-47\\model\n",
      "n_cust: 10\n",
      "n_glimpses: 0\n",
      "n_nodes: 11\n",
      "n_process_blocks: 3\n",
      "n_train: 260000\n",
      "random_seed: 24601\n",
      "rnn_layers: 1\n",
      "save_interval: 1000\n",
      "stdout_print: True\n",
      "tanh_exploration: 10.0\n",
      "task: vrp10\n",
      "task_name: vrp\n",
      "test_interval: 200\n",
      "test_size: 1000\n",
      "ups: False\n",
      "use_tanh: False\n",
      "# Set random seed to 24601\n",
      "Created train iterator.\n",
      "Loading dataset for vrp-size-1000-len-11-test.txt...\n",
      "WARNING:tensorflow:From E:\\GitHub\\TF4AI_practice\\vrp\\shared\\decode_step.py:175: BasicLSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From E:\\GitHub\\TF4AI_practice\\vrp\\shared\\decode_step.py:180: MultiRNNCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From E:\\GitHub\\TF4AI_practice\\vrp\\shared\\decode_step.py:211: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From E:\\anaconda\\envs\\vrp\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:738: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From E:\\anaconda\\envs\\vrp\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:744: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From E:\\GitHub\\TF4AI_practice\\vrp\\model\\attention_agent.py:268: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From E:\\anaconda\\envs\\vrp\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "It took 28.79093098640442s to build the agent.\n",
      "Training started ...\n",
      "Train Step: 0 -- Time: 00:00:40 -- Embedding Time 00:00:09 -- Train reward: 7.734752655029297 -- Value: 0.06319811940193176\n",
      "    actor loss: -158.04415893554688 -- critic loss: 61.12965393066406\n",
      "Average of greedy in batch-mode: 10.047117233276367 -- std 2.2434463500976562 -- time 4.205431222915649 s\n",
      "Average of beam_search in batch-mode: 9.350543975830078 -- std 2.222659111022949 -- time 5.3369057178497314 s\n",
      "##################################################################\n",
      "Train Step: 200 -- Time: 00:01:04 -- Embedding Time 00:00:00 -- Train reward: 7.391831398010254 -- Value: 7.180556297302246\n",
      "    actor loss: -4.47226095199585 -- critic loss: 2.7457423210144043\n",
      "Average of greedy in batch-mode: 7.471275329589844 -- std 1.3137266635894775 -- time 2.193725109100342 s\n",
      "Average of beam_search in batch-mode: 7.013428688049316 -- std 1.2777940034866333 -- time 3.1641571521759033 s\n",
      "##################################################################\n",
      "Train Step: 400 -- Time: 00:01:15 -- Embedding Time 00:00:00 -- Train reward: 7.209929943084717 -- Value: 6.905607223510742\n",
      "    actor loss: -4.886992454528809 -- critic loss: 2.401280641555786\n",
      "Average of greedy in batch-mode: 7.054971694946289 -- std 1.2121341228485107 -- time 2.1972568035125732 s\n",
      "Average of beam_search in batch-mode: 6.565552234649658 -- std 1.1370538473129272 -- time 3.2430644035339355 s\n",
      "##################################################################\n",
      "Train Step: 600 -- Time: 00:01:21 -- Embedding Time 00:00:00 -- Train reward: 7.074225425720215 -- Value: 7.014246940612793\n",
      "    actor loss: -1.3185198307037354 -- critic loss: 2.458232879638672\n",
      "Average of greedy in batch-mode: 6.983089447021484 -- std 1.1635578870773315 -- time 2.248194456100464 s\n",
      "Average of beam_search in batch-mode: 6.51982307434082 -- std 1.1234875917434692 -- time 3.255249261856079 s\n",
      "##################################################################\n",
      "Train Step: 800 -- Time: 00:01:31 -- Embedding Time 00:00:00 -- Train reward: 7.193115234375 -- Value: 6.867886543273926\n",
      "    actor loss: -4.063915729522705 -- critic loss: 2.418637275695801\n",
      "Average of greedy in batch-mode: 6.909358978271484 -- std 1.1568349599838257 -- time 2.2475051879882812 s\n",
      "Average of beam_search in batch-mode: 6.455380916595459 -- std 1.1017661094665527 -- time 3.257664680480957 s\n",
      "##################################################################\n",
      "Train Step: 1000 -- Time: 00:02:10 -- Embedding Time 00:00:00 -- Train reward: 7.022283554077148 -- Value: 6.892385482788086\n",
      "    actor loss: -1.842239260673523 -- critic loss: 1.7583550214767456\n",
      "Average of greedy in batch-mode: 6.910676956176758 -- std 1.1879647970199585 -- time 2.2773241996765137 s\n",
      "Average of beam_search in batch-mode: 6.396679401397705 -- std 1.0812981128692627 -- time 3.31109356880188 s\n",
      "##################################################################\n",
      "Train Step: 1200 -- Time: 00:01:37 -- Embedding Time 00:00:00 -- Train reward: 7.0138325691223145 -- Value: 6.804394245147705\n",
      "    actor loss: -2.5127124786376953 -- critic loss: 1.7959768772125244\n",
      "Average of greedy in batch-mode: 6.886906147003174 -- std 1.1660279035568237 -- time 2.2840394973754883 s\n",
      "Average of beam_search in batch-mode: 6.401505947113037 -- std 1.088470220565796 -- time 3.333618402481079 s\n",
      "##################################################################\n",
      "Train Step: 1400 -- Time: 00:01:42 -- Embedding Time 00:00:00 -- Train reward: 6.877704620361328 -- Value: 6.8065338134765625\n",
      "    actor loss: -0.8050606846809387 -- critic loss: 1.378703236579895\n",
      "Average of greedy in batch-mode: 6.852275848388672 -- std 1.1676533222198486 -- time 2.307077646255493 s\n",
      "Average of beam_search in batch-mode: 6.392573356628418 -- std 1.0686653852462769 -- time 3.2867658138275146 s\n",
      "##################################################################\n",
      "Train Step: 1600 -- Time: 00:01:46 -- Embedding Time 00:00:00 -- Train reward: 6.9764862060546875 -- Value: 6.899600028991699\n",
      "    actor loss: -1.2332075834274292 -- critic loss: 1.345867395401001\n",
      "Average of greedy in batch-mode: 6.856788158416748 -- std 1.1524046659469604 -- time 2.3529276847839355 s\n",
      "Average of beam_search in batch-mode: 6.386476516723633 -- std 1.0680104494094849 -- time 3.3306727409362793 s\n",
      "##################################################################\n",
      "Train Step: 1800 -- Time: 00:01:49 -- Embedding Time 00:00:00 -- Train reward: 6.9005937576293945 -- Value: 6.714104652404785\n",
      "    actor loss: -2.3020596504211426 -- critic loss: 1.3202906847000122\n",
      "Average of greedy in batch-mode: 6.847030162811279 -- std 1.1389671564102173 -- time 2.347838878631592 s\n",
      "Average of beam_search in batch-mode: 6.382593154907227 -- std 1.0381360054016113 -- time 3.37754225730896 s\n",
      "##################################################################\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def load_task_specific_components(task,ups):\n",
    "    '''\n",
    "    This function load task-specific libraries\n",
    "    '''\n",
    "    if task == 'vrp':\n",
    "        if ups:\n",
    "            from UPS.vrp_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrp_ups_attention import AttentionVRP_UPS_Actor, AttentionVRP_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRP_UPS_Actor\n",
    "            AttentionCritic = AttentionVRP_UPS_Critic\n",
    "\n",
    "        else:\n",
    "            from VRP.vrp_utils import DataGenerator,Env,reward_func\n",
    "            from VRP.vrp_attention import AttentionVRPActor,AttentionVRPCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPActor\n",
    "            AttentionCritic = AttentionVRPCritic\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        if ups:\n",
    "            from UPS.vrptw_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrptw_ups_attention import AttentionVRPTW_UPS_Actor, AttentionVRPTW_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRPTW_UPS_Actor\n",
    "            AttentionCritic = AttentionVRPTW_UPS_Critic\n",
    "        else:\n",
    "            from VRPTW.vrptw_utils import DataGenerator,Env,reward_func\n",
    "            from VRPTW.vrptw_attention import AttentionVRPTWActor, AttentionVRPTWCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPTWActor\n",
    "            AttentionCritic = AttentionVRPTWCritic\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')\n",
    "\n",
    "    return DataGenerator, Env, reward_func, AttentionActor, AttentionCritic\n",
    "\n",
    "\n",
    "def load_task_specific_eval(task):\n",
    "    \"\"\"\n",
    "    Load taks specific, dependign of tw or not\n",
    "    \"\"\"\n",
    "    if task == 'vrp':\n",
    "        from evaluation.eval_VRP import eval_google_or,eval_Clarke_Wright\n",
    "\n",
    "        return [(eval_google_or.EvalGoogleOR,'or_tools'), (eval_Clarke_Wright.EvalClarkeWright,'Clarke_Wright')]\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        from evaluation.eval_VRPTW import eval_tw_google_or,eval_I1_heuristics\n",
    "\n",
    "        return [(eval_tw_google_or.EvalTWGoogleOR,'or_tools_tw'),(eval_I1_heuristics.EvalI1Heuristics,'I1_heuristic')]\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')\n",
    "\n",
    "\n",
    "def main(args, prt):\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    \n",
    "    # load task specific classes\n",
    "    DataGenerator, Env, reward_func, AttentionActor, AttentionCritic = \\\n",
    "        load_task_specific_components(args['task_name'],args['ups'])\n",
    "\n",
    "    dataGen = DataGenerator(args)\n",
    "    dataGen.reset()\n",
    "    env = Env(args)\n",
    "    # create an RL agent\n",
    "    agent = RLAgent(args,\n",
    "                    prt,\n",
    "                    env,\n",
    "                    dataGen,\n",
    "                    reward_func,\n",
    "                    AttentionActor,\n",
    "                    AttentionCritic,\n",
    "                    is_train=args['is_train'])\n",
    "    agent.Initialize(sess)\n",
    "\n",
    "    # train or evaluate\n",
    "    prev_actor_loss, prev_critic_loss = float('Inf'), float('Inf')\n",
    "    actor_eps, critic_eps = 1e-2, 1e-2\n",
    "    start_time = time.time()\n",
    "    convergence_counter = 0\n",
    "    al_file = open(args['log_dir']+\"/actorLoss.txt\", \"w\")\n",
    "    cl_file = open(args['log_dir']+\"/criticLoss.txt\", \"w\")\n",
    "    r_file = open(args['log_dir']+\"/reward.txt\", \"w\")\n",
    "\n",
    "    if args['is_train']:\n",
    "        prt.print_out('Training started ...')\n",
    "        train_time_beg = time.time()\n",
    "        for step in range(args['n_train']):\n",
    "            summary = agent.run_train_step()\n",
    "            _, _ , actor_loss_val, critic_loss_val, actor_gra_and_var_val, critic_gra_and_var_val,\\\n",
    "                R_val, v_val, logprobs_val,probs_val, actions_val, idxs_val= summary\n",
    "\n",
    "            curr_actor_loss = np.mean(actor_loss_val)\n",
    "            curr_critic_loss = np.mean(critic_loss_val)\n",
    "            al_file.write( str(actor_loss_val) + '\\n')\n",
    "            cl_file.write(str(critic_loss_val) + '\\n')\n",
    "            r_file.write(str(np.mean(R_val)) + '\\n')\n",
    "\n",
    "            if abs(prev_actor_loss - curr_actor_loss) < actor_eps \\\n",
    "                and abs(prev_critic_loss - curr_critic_loss) < critic_eps:\n",
    "                convergence_counter += 1\n",
    "            else:\n",
    "                convergence_counter = 0\n",
    "            if convergence_counter == 10:\n",
    "                prt.print_out('Converged at step {}'\\\n",
    "                      .format(step))\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss,curr_critic_loss))\n",
    "                break\n",
    "\n",
    "            if step%args['save_interval'] == 0:\n",
    "                agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "            if step%args['log_interval'] == 0:\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Embedding Time {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        agent.embedder_model.total_time)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss, curr_critic_loss))\n",
    "\n",
    "                train_time_beg = time.time()\n",
    "                agent.embedder_model.total_time = 0\n",
    "            if step%args['test_interval'] == 0:\n",
    "                agent.inference(args['infer_type'])\n",
    "            prev_actor_loss = curr_actor_loss\n",
    "            prev_critic_loss = curr_critic_loss\n",
    "\n",
    "        # Save the model at the end of the training\n",
    "        agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "    else: # inference\n",
    "        prt.print_out('Evaluation started ...')\n",
    "        agent.inference(args['infer_type'])\n",
    "\n",
    "        all_evaluator = load_task_specific_eval(args['task_name'])\n",
    "\n",
    "        # perform the evaluation\n",
    "        list_eval = ['beam_search'] #['greedy','beam_search']\n",
    "        for eval_tuple in all_evaluator:\n",
    "            list_eval.append(eval_tuple[1])\n",
    "\n",
    "            object_eval = eval_tuple[0](args,env,prt,args['min_trucks'])\n",
    "            object_eval.perform_routing()\n",
    "        #\n",
    "        benchmark_object = benchmark.Benchmark(args,env,prt)\n",
    "        # list_eval.remove('Clarke_Wright')\n",
    "        # #list_eval.remove('I1_heuristic')\n",
    "        benchmark_object.perform_benchmark(list_eval=list_eval)\n",
    "\n",
    "    prt.print_out('Total time is {}'.format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time))))\n",
    "    al_file.close()\n",
    "    cl_file.close()\n",
    "    r_file.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "    #assert False\n",
    "    args, prt = ParseParams()\n",
    "    args['is_train'] = True\n",
    "    # args['infer_type'] = 'single'\n",
    "    args['test_size'] = 1000\n",
    "   #  args['log_dir'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp20-2019-12-05_09-28-11/\"\n",
    "    # args['load_path'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp50-NbTruck/model/\"\n",
    "\n",
    "    # args['data_dir'] = \"drive/My Drive/VRP-RL/data\"\n",
    "    # args['log_dir'] = \"drive/My Drive/VRP-RL/logs\"\n",
    "    # args['log_dir'] = \"{}/{}-{}\".format(args['log_dir'],args['task'], utils.get_time())\n",
    "    # print(args['log_dir'])\n",
    "    # args['model_dir'] = os.path.join(args['log_dir'],'model')\n",
    "    #\n",
    "    # args['load_path'] = \"drive/My Drive/VRP-RL/logs/vrptw50-2019-11-25_01-28-09/model/\"\n",
    "    # print(args['model_dir'])\n",
    "    # # file to write the stdout\n",
    "    # try:\n",
    "    #     os.makedirs(args['log_dir'])\n",
    "    #     os.makedirs(args['model_dir'])\n",
    "    # except:\n",
    "    #     pass\n",
    "    #\n",
    "    # # create a print handler\n",
    "    # out_file = open(os.path.join(args['log_dir'], 'results.txt'),'w+')\n",
    "    # prt = utils.printOut(out_file,args['stdout_print'])\n",
    "\n",
    "    # Random\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    random_seed = args['random_seed']\n",
    "    if random_seed is not None and random_seed > 0:\n",
    "        prt.print_out(\"# Set random seed to %d\" % random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    main(args, prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6d2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea0b74-a002-4809-9f04-4ab410df642e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3eb12-3695-474b-a493-158d88580cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

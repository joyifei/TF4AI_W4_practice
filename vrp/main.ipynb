{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import shared.misc_utils as utils\n",
    "\n",
    "from configs import ParseParams\n",
    "\n",
    "#from shared import embeddings\n",
    "11\n",
    "from evaluation.benchmark import benchmark\n",
    "#from model.attention_agent import RLAgent\n",
    "\n",
    "import pickle,time,os\n",
    "\n",
    "from configs import ParseParams\n",
    "from shared.graph_embedding.useful_files.gnn_film_model import GNN_FiLM_Model\n",
    "from shared.graph_embedding.useful_files.number_vehicle_task import Nb_Vehicles_Task\n",
    "from VRP.vrp_utils import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e524419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os\n",
    "\n",
    "from shutil import copyfile\n",
    "from sklearn.preprocessing import normalize\n",
    "from shared.embeddings import LinearEmbedding,GraphEmbedding\n",
    "from shared.graph_embedding.full_graph_learning import FullGraphEmbedding\n",
    "from shared.decode_step import RNNDecodeStep\n",
    "\n",
    "class RLAgent(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                args,\n",
    "                prt,\n",
    "                env,\n",
    "                dataGen,\n",
    "                reward_func,\n",
    "                clAttentionActor,\n",
    "                clAttentionCritic,\n",
    "                is_train=True,\n",
    "                _scope=''):\n",
    "        '''\n",
    "        This class builds the model and run testt and train.\n",
    "        Inputs:\n",
    "            args: arguments. See the description in config.py file.\n",
    "            prt: print controller which writes logs to a file.\n",
    "            env: an instance of the environment.\n",
    "            dataGen: a data generator which generates data for test and training.\n",
    "            reward_func: the function which is used for computing the reward. It returns the tour length.\n",
    "            clAttentionActor: Attention mechanism that is used in actor.\n",
    "            clAttentionCritic: Attention mechanism that is used in critic.\n",
    "            is_train: if true, the agent is used for training; else, it is used only\n",
    "                        for inference.\n",
    "        '''\n",
    "\n",
    "        self.args = args\n",
    "        self.prt = prt\n",
    "        self.env = env\n",
    "        self.dataGen = dataGen\n",
    "        self.reward_func = reward_func\n",
    "        self.clAttentionCritic = clAttentionCritic\n",
    "\n",
    "        if args['embedding_graph'] == 2:\n",
    "            self.embedder_model = FullGraphEmbedding(args['embedding_dim'],args)\n",
    "        else:\n",
    "            self.embedder_model = LinearEmbedding(args['embedding_dim'],_scope=_scope+'Actor/')\n",
    "\n",
    "        if args['embedding_graph'] ==1:\n",
    "            data_test = self.dataGen.get_test_all()\n",
    "            self.embedder_graph = GraphEmbedding(args,data_test)\n",
    "\n",
    "\n",
    "\n",
    "        self.decodeStep = RNNDecodeStep(clAttentionActor,\n",
    "                        args['hidden_dim'],\n",
    "                        use_tanh=args['use_tanh'],\n",
    "                        tanh_exploration=args['tanh_exploration'],\n",
    "                        n_glimpses=args['n_glimpses'],\n",
    "                        mask_glimpses=args['mask_glimpses'],\n",
    "                        mask_pointer=args['mask_pointer'],\n",
    "                        forget_bias=args['forget_bias'],\n",
    "                        rnn_layers=args['rnn_layers'],\n",
    "                        _scope='Actor/')\n",
    "        self.decoder_input = tf.compat.v1.get_variable('decoder_input', [1,1,args['embedding_dim']],\n",
    "                       initializer=tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"))\n",
    "\n",
    "        start_time  = time.time()\n",
    "        if is_train:\n",
    "            self.train_summary = self.build_model(decode_type = \"stochastic\" )\n",
    "            self.train_step = self.build_train_step()\n",
    "\n",
    "        self.val_summary_greedy = self.build_model(decode_type = \"greedy\" )\n",
    "        self.val_summary_beam = self.build_model(decode_type = \"beam_search\")\n",
    "\n",
    "        model_time = time.time()- start_time\n",
    "        self.prt.print_out(\"It took {}s to build the agent.\".format(str(model_time)))\n",
    "\n",
    "        self.saver = tf.compat.v1.train.Saver(\n",
    "            var_list=tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        self.out_avg_resul = open(args['log_dir']+\"/avg_inference.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491cb3f3-c67c-4602-bc19-3480dc5e845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "from shared.embeddings import Embedding\n",
    "from shared.graph_embedding.useful_files.utils import get_activation\n",
    "from shared.graph_embedding.useful_files.gnn_film import sparse_gnn_film_layer\n",
    "\n",
    "class FullGraphEmbedding(Embedding):\n",
    "    \"\"\"\n",
    "    Implements a graph embedding, not test\n",
    "    \"\"\"\n",
    "    def __init__(self,embedding_dim,args):\n",
    "        assert args['embedding_dim'] == 30, args['embedding_dim']\n",
    "        super(FullGraphEmbedding,self).__init__('full_graph',embedding_dim)\n",
    "\n",
    "        self.nb_feat = args['input_dim']\n",
    "        self.n_nodes = args['n_nodes']\n",
    "\n",
    "        self._scale = [5,12,25,50,100]\n",
    "        self._scale = [i * np.sqrt(2)/100 for i in self._scale]     # rescale to the square\n",
    "\n",
    "        self.drop_out = tf.compat.v1.placeholder(tf.float32,name='embedder_graph_dropout')\n",
    "        self.params = {\n",
    "            'graph_num_layers': 8,\n",
    "            'graph_num_timesteps_per_layer': 3,\n",
    "\n",
    "            'graph_layer_input_dropout_keep_prob': 0.8,\n",
    "            'graph_dense_between_every_num_gnn_layers': 1,\n",
    "            'graph_model_activation_function': 'tanh',\n",
    "            'graph_residual_connection_every_num_layers': 1,\n",
    "            'graph_inter_layer_norm': False,\n",
    "            \"hidden_size\": 30,\n",
    "            \"graph_activation_function\": \"ReLU\",\n",
    "            \"message_aggregation_function\": \"sum\",\n",
    "            \"normalize_messages_by_num_incoming\": True\n",
    "            }\n",
    "\n",
    "\n",
    "    def _propagate_graph_model(self,initial_node_features, incoming_edge, list_pair_adjancy):\n",
    "        \"\"\"\n",
    "        Build the propagation model via graph\n",
    "        :param initial_node_features:\n",
    "        :param incoming_edge:\n",
    "        :param list_pair_adjancy:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        h_dim= self.params['hidden_size']\n",
    "        activation_fn = get_activation(self.params['graph_model_activation_function'])\n",
    "\n",
    "        projected_node_features = tf.keras.layers.Dense(units=h_dim,\n",
    "                                      use_bias=False,\n",
    "                                      activation=activation_fn,\n",
    "                                      )(initial_node_features)\n",
    "\n",
    "        cur_node_representations = projected_node_features\n",
    "        last_residual_representations = tf.zeros_like(cur_node_representations)\n",
    "        for layer_idx in range(self.params['graph_num_layers']):\n",
    "            # with tf.variable_scope('gnn_layer_%i' % layer_idx):\n",
    "            cur_node_representations = \\\n",
    "                tf.nn.dropout(cur_node_representations, rate= 1- self.drop_out)\n",
    "            if layer_idx % self.params['graph_residual_connection_every_num_layers'] == 0:\n",
    "                t = cur_node_representations\n",
    "                if layer_idx > 0:\n",
    "                    cur_node_representations += last_residual_representations\n",
    "                    cur_node_representations /= 2\n",
    "                last_residual_representations = t\n",
    "            cur_node_representations = \\\n",
    "                self._apply_gnn_layer(cur_node_representations,list_pair_adjancy,incoming_edge,self.params['graph_num_timesteps_per_layer'])\n",
    "            if self.params['graph_inter_layer_norm']:\n",
    "                cur_node_representations = tf.contrib.layers.layer_norm(cur_node_representations)\n",
    "            if layer_idx % self.params['graph_dense_between_every_num_gnn_layers'] == 0:\n",
    "                cur_node_representations = \\\n",
    "                    tf.keras.layers.Dense(units=h_dim,\n",
    "                                          use_bias=False,\n",
    "                                          activation=activation_fn,\n",
    "                                          name=\"Dense\",\n",
    "                                          )(cur_node_representations)\n",
    "\n",
    "        return cur_node_representations\n",
    "\n",
    "\n",
    "    def _apply_gnn_layer(self,node_representations,adjacency_lists,type_to_num_incoming_edges,num_timesteps):\n",
    "        \"\"\"\n",
    "        Apply the actual gnn layer\n",
    "        \"\"\"\n",
    "        return sparse_gnn_film_layer(\n",
    "            node_embeddings=node_representations,\n",
    "            adjacency_lists=adjacency_lists,\n",
    "            type_to_num_incoming_edges=type_to_num_incoming_edges,\n",
    "            state_dim=self.params['hidden_size'],\n",
    "            num_timesteps=num_timesteps,\n",
    "            activation_function=self.params['graph_activation_function'],\n",
    "            message_aggregation_function=self.params['message_aggregation_function'],\n",
    "            normalize_by_num_incoming=self.params[\"normalize_messages_by_num_incoming\"])\n",
    "\n",
    "\n",
    "    def _prepare_input_data(self, input_tf):\n",
    "        \"\"\"\n",
    "        Prepare the input data so that they are at the right size\n",
    "        :param input_tf:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #shape of input_tf is [None, 11, 3] which mean undetermined batches, 11 nodes,  andd 3 columne for each node to list the x, y coordinate and demand qty\n",
    "        batch_features = tf.reshape(input_tf,[-1,self.nb_feat])\n",
    "        #batch features are put the nodes infor together,  into shape [None, 3]\n",
    "        input_dist = input_tf[:,:,:2]\n",
    "        square_input = tf.reduce_sum(input_tensor=tf.square(input_dist), axis=2)\n",
    "        row = tf.reshape(square_input, [-1,self.n_nodes,1])\n",
    "        col= tf.reshape(square_input,[-1,1,self.n_nodes])\n",
    "        dist_matrix = tf.sqrt(tf.maximum(row - 2 * tf.matmul(input_dist,input_dist,False,True) + col,0.0))\n",
    "        #shape of dist_matrix would be [?, self.n_nodes, self.n_nodes]\n",
    "        # value is the distance between nodes,  coordinate of node Ni is (Xi1, Xi2), and node Nj is (Xj1, Xj2)\n",
    "        #then the value in the maxtrix for position[ ?, i, j] would be sqrt( (Xi1 - Xj1 ) ^2 + (Xi2 - Xj2)^2 )\n",
    "        # example dist_matrix: \n",
    "        # dist_matrix: \n",
    "        # tf.Tensor(\n",
    "        #[[[ 0.         4.2426405  8.485281  12.7279215]\n",
    "        #  [ 4.2426405  0.         4.2426405  8.485281 ]\n",
    "        #  [ 8.485281   4.2426405  0.         4.2426405]\n",
    "        #  [12.7279215  8.485281   4.2426405  0.       ]]\n",
    "        # [[ 0.         4.2426405  8.485281  12.7279215]\n",
    "        #  [ 4.2426405  0.         4.2426405  8.485281 ]\n",
    "        #  [ 8.485281   4.2426405  0.         4.2426405]\n",
    "        #  [12.7279215  8.485281   4.2426405  0.       ]]], shape=(2, 4, 4), \n",
    "        list_num_incoming_ege = []\n",
    "        list_pair_edge = []\n",
    "        # not_masked is a [?, self.n_nodes, self.n_nodes] shape boolean tensor, all intial values are true\n",
    "        not_masked = tf.ones_like(dist_matrix,dtype=tf.bool)\n",
    "        temp = tf.zeros_like(not_masked[0,:,:])\n",
    "        #so set_diag will set the diagnal values to zeros, like:\n",
    "        #  [ [0, 1, 1, 1],\n",
    "        #    [1, 0, 1, 1],\n",
    "        #    [1, 1, 0, 1],\n",
    "        tf.linalg.set_diag(not_masked,tf.zeros_like(not_masked[0,:,:]))\n",
    "        \n",
    "        for i in range(len(self._scale)):\n",
    "            true_for_edge = tf.less_equal(dist_matrix,self._scale[i])\n",
    "            true_for_edge = tf.logical_and(not_masked,true_for_edge)\n",
    "            # continue above example , \n",
    "            # true for edge less than 5.0: \n",
    "            #tf.Tensor(\n",
    "            #[[[ True  True False False]\n",
    "            #  [ True  True  True False]\n",
    "            #  [False  True  True  True]\n",
    "            #  [False False  True  True]]\n",
    "            # [[ True  True False False]\n",
    "            #  [ True  True  True False]\n",
    "            #  [False  True  True  True]\n",
    "            #  [False False  True  True]]], shape=(2, 4, 4), dtype=bool)\n",
    "            \n",
    "            # all values less than self._scale[i] are true,  and diagnal values are false\n",
    "            # same shape as dist_matrix [?,n,n]\n",
    "            indices = tf.cast(tf.compat.v1.where(true_for_edge),dtype=tf.int32)\n",
    "            #indices of  coordinates of all the edges in dist_matrix with value less than self._scale[i]\n",
    "            offset = self.n_nodes * indices[:,0]    # get all batch value\n",
    "             #batch 1,2, 11 nodes,  offset would be [11, 11, 11, ....11, 22, 22, 22, ...22]\n",
    "            offset = tf.expand_dims(offset,axis=1)\n",
    "            #after expending become: [[11],[11],...[11],[22],[22],...[22]]\n",
    "            offset = tf.tile(offset,[1,2])\n",
    "            #after tiline become:  [[11,11],[11,11],...[11,11],[22,22], [22,22],...[22]]\n",
    "            #indices[:,1:3] is the index of last two column,  so really the edge (from node to 'to node')\n",
    "            true_indices_nodes = offset + indices[:,1:3]\n",
    "            # so now actually true_indices_nodes is like embedding the batching dimension into the edge columns\n",
    "            list_pair_edge.append(true_indices_nodes)\n",
    "\n",
    "            num_incoming = tf.reduce_sum(input_tensor=tf.cast(true_for_edge,dtype=tf.int32), axis=1)\n",
    "            # continue examples， num incoming: \n",
    "            #tf.Tensor(\n",
    "            #[[2 3 3 2]\n",
    "            # [2 3 3 2]], shape=(2, 4), dtype=int32)\n",
    "            \n",
    "            num_incoming = tf.squeeze(tf.reshape(num_incoming,[1,-1]),0)\n",
    "            # reshaped: tf.Tensor([[2 3 3 2 2 3 3 2]], shape=(1, 8), dtype=int32)\n",
    "            # squeezed: tf.Tensor([2 3 3 2 2 3 3 2], shape=(8,), dtype=int32)\n",
    "            list_num_incoming_ege.append(tf.cast(num_incoming,dtype=tf.float32))\n",
    "            # list_num_incoming_ege is a list of 5 tensor\n",
    "            # update the mask\n",
    "            not_masked = tf.logical_and(not_masked,tf.logical_not(true_for_edge)) # we update the mask. The only one not masked are the one wich\n",
    "                                                                                    # were not and did not belong to the edge type\n",
    "        final_incoming_edge = tf.stack(list_num_incoming_ege)\n",
    "\n",
    "\n",
    "        return batch_features, final_incoming_edge, list_pair_edge\n",
    "\n",
    "    def __call__(self, input_tf):\n",
    "        \"\"\"\n",
    "        return the node embedding\n",
    "        :param input_tf: the tensor corresponding to the embedding\n",
    "        :return: a tensor\n",
    "        \"\"\"\n",
    "        time_init = time.time()\n",
    "        initial_node_features, incoming_edge, list_pair_adjancy = self._prepare_input_data(input_tf)\n",
    "\n",
    "        final_node_representations = self._propagate_graph_model(initial_node_features,incoming_edge,list_pair_adjancy)\n",
    "        final_node_representations = tf.reshape(final_node_representations,[-1,self.n_nodes,self.embedding_dim])\n",
    "\n",
    "        self.total_time += time.time() - time_init\n",
    "\n",
    "        return final_node_representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673eb1d0-67bb-422f-b563-a9e320631646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent( RLAgent ):\n",
    "    def build_model(self, decode_type = \"greedy\"):\n",
    "\n",
    "        # builds the model\n",
    "        args = self.args\n",
    "        env = self.env\n",
    "        batch_size = tf.shape(input=env.input_pnt)[0]\n",
    "\n",
    "        # input_pnt: [batch_size x max_time x dim_task]\n",
    "        input_pnt = env.input_pnt\n",
    "\n",
    "        # encoder_emb_inp: [batch_size, max_time, embedding_dim]\n",
    "        if self.args['embedding_graph'] == 0:\n",
    "            encoder_emb_inp = self.embedder_model(input_pnt)\n",
    "        elif self.args['embedding_graph'] == 1:\n",
    "            encoder_emb_inp = self.env.embeded_data\n",
    "        else:\n",
    "            encoder_emb_inp = self.embedder_model(env.input_data_norm)\n",
    "\n",
    "        if decode_type == 'greedy' or decode_type == 'stochastic':\n",
    "            beam_width = 1\n",
    "        elif decode_type == 'beam_search':\n",
    "            beam_width = args['beam_width']\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        # reset the env. The environment is modified to handle beam_search decoding.\n",
    "        env.reset(beam_width)\n",
    "\n",
    "        BatchSequence = tf.expand_dims(tf.cast(tf.range(batch_size*beam_width), tf.int64), 1)\n",
    "\n",
    "\n",
    "        # create tensors and lists\n",
    "        actions_tmp = []\n",
    "        logprobs = []\n",
    "        probs = []\n",
    "        idxs = []\n",
    "\n",
    "        # start from depot\n",
    "        idx = (env.n_nodes-1)*tf.ones([batch_size*beam_width,1])\n",
    "        action = tf.tile(input_pnt[:,env.n_nodes-1],[beam_width,1])\n",
    "\n",
    "        # decoder_state\n",
    "        initial_state = tf.zeros([args['rnn_layers'], 2, batch_size*beam_width, args['hidden_dim']])\n",
    "        l = tf.unstack(initial_state, axis=0)\n",
    "        decoder_state = tuple([tf.compat.v1.nn.rnn_cell.LSTMStateTuple(l[idx][0],l[idx][1])\n",
    "                  for idx in range(args['rnn_layers'])])\n",
    "\n",
    "        # start from depot in VRP\n",
    "        # decoder_input: [batch_size*beam_width x 1 x hidden_dim]\n",
    "        decoder_input = tf.tile(tf.expand_dims(encoder_emb_inp[:,env.n_nodes-1], 1),\n",
    "                                [beam_width,1,1])\n",
    "\n",
    "        # decoding loop\n",
    "        context = tf.tile(encoder_emb_inp,[beam_width,1,1])\n",
    "        for i in range(args['decode_len']):\n",
    "\n",
    "            logit, prob, logprob, decoder_state = self.decodeStep.step(decoder_input,\n",
    "                                context,\n",
    "                                env,\n",
    "                                decoder_state)\n",
    "            # idx: [batch_size*beam_width x 1]\n",
    "            beam_parent = None\n",
    "            if decode_type == 'greedy':\n",
    "                idx = tf.expand_dims(tf.argmax(input=prob, axis=1),1)\n",
    "            elif decode_type == 'stochastic':\n",
    "                # select stochastic actions. idx has shape [batch_size x 1]\n",
    "                # tf.multinomial sometimes gives numerical errors, so we use our multinomial :(\n",
    "                def my_multinomial():\n",
    "                    prob_idx = tf.stop_gradient(prob)\n",
    "                    prob_idx_cum = tf.cumsum(prob_idx,1)\n",
    "                    rand_uni = tf.tile(tf.random.uniform([batch_size,1]),[1,env.n_nodes])\n",
    "                    # sorted_ind : [[0,1,2,3..],[0,1,2,3..] , ]\n",
    "                    sorted_ind = tf.cast(tf.tile(tf.expand_dims(tf.range(env.n_nodes),0),[batch_size,1]),tf.int64)\n",
    "                    tmp = tf.multiply(tf.cast(tf.greater(prob_idx_cum,rand_uni),tf.int64), sorted_ind)+\\\n",
    "                        10000*tf.cast(tf.greater_equal(rand_uni,prob_idx_cum),tf.int64)\n",
    "\n",
    "                    idx = tf.expand_dims(tf.argmin(input=tmp,axis=1),1)\n",
    "                    return tmp, idx\n",
    "\n",
    "                tmp, idx = my_multinomial()\n",
    "                # check validity of tmp -> True or False -- True mean take a new sample\n",
    "                tmp_check = tf.cast(tf.reduce_sum(input_tensor=tf.cast(tf.greater(tf.reduce_sum(input_tensor=tmp,axis=1),(10000*env.n_nodes)-1),\n",
    "                                                          tf.int32)),tf.bool)\n",
    "                tmp , idx = tf.cond(pred=tmp_check,true_fn=my_multinomial,false_fn=lambda:(tmp,idx))\n",
    "\n",
    "            elif decode_type == 'beam_search':\n",
    "                if i==0:\n",
    "                    # BatchBeamSeq: [batch_size*beam_width x 1]\n",
    "                    # [0,1,2,3,...,127,0,1,...],\n",
    "                    batchBeamSeq = tf.expand_dims(tf.tile(tf.cast(tf.range(batch_size), tf.int64),\n",
    "                                                         [beam_width]),1)\n",
    "                    beam_path  = []\n",
    "                    log_beam_probs = []\n",
    "                    # in the initial decoder step, we want to choose beam_width different branches\n",
    "                    # log_beam_prob: [batch_size, sourceL]\n",
    "                    log_beam_prob = tf.math.log(tf.split(prob,num_or_size_splits=beam_width, axis=0)[0])\n",
    "\n",
    "                elif i > 0:\n",
    "                    log_beam_prob = tf.math.log(prob) + log_beam_probs[-1]\n",
    "                    # log_beam_prob:[batch_size, beam_width*sourceL]\n",
    "                    log_beam_prob = tf.concat(tf.split(log_beam_prob, num_or_size_splits=beam_width, axis=0),1)\n",
    "\n",
    "                # topk_prob_val,topk_logprob_ind: [batch_size, beam_width]\n",
    "                topk_logprob_val, topk_logprob_ind = tf.nn.top_k(log_beam_prob, beam_width)\n",
    "\n",
    "                # topk_logprob_val , topk_logprob_ind: [batch_size*beam_width x 1]\n",
    "                topk_logprob_val = tf.transpose(a=tf.reshape(\n",
    "                    tf.transpose(a=topk_logprob_val), [1,-1]))\n",
    "\n",
    "                topk_logprob_ind = tf.transpose(a=tf.reshape(\n",
    "                    tf.transpose(a=topk_logprob_ind), [1,-1]))\n",
    "\n",
    "                #idx,beam_parent: [batch_size*beam_width x 1]\n",
    "                idx = tf.cast(topk_logprob_ind % env.n_nodes, tf.int64) # Which city in route.\n",
    "                beam_parent = tf.cast(topk_logprob_ind // env.n_nodes, tf.int64) # Which hypothesis it came from.\n",
    "\n",
    "                # batchedBeamIdx:[batch_size*beam_width]\n",
    "                batchedBeamIdx= batchBeamSeq + tf.cast(batch_size,tf.int64)*beam_parent\n",
    "                prob = tf.gather_nd(prob,batchedBeamIdx)\n",
    "\n",
    "                beam_path.append(beam_parent)\n",
    "                log_beam_probs.append(topk_logprob_val)\n",
    "\n",
    "            state = env.step(idx,beam_parent)\n",
    "            batched_idx = tf.concat([BatchSequence,idx],1)\n",
    "\n",
    "\n",
    "            decoder_input = tf.expand_dims(tf.gather_nd(\n",
    "                tf.tile(encoder_emb_inp,[beam_width,1,1]), batched_idx),1)\n",
    "\n",
    "            logprob = tf.math.log(tf.gather_nd(prob, batched_idx))\n",
    "            probs.append(prob)\n",
    "            idxs.append(idx)\n",
    "            logprobs.append(logprob)\n",
    "\n",
    "            action = tf.gather_nd(tf.tile(input_pnt, [beam_width,1,1]), batched_idx )\n",
    "            actions_tmp.append(action)\n",
    "\n",
    "        if decode_type=='beam_search':\n",
    "            # find paths of the beam search\n",
    "            tmplst = []\n",
    "            tmpind = [BatchSequence]\n",
    "            for k in reversed(range(len(actions_tmp))):\n",
    "\n",
    "                tmplst = [tf.gather_nd(actions_tmp[k],tmpind[-1])] + tmplst\n",
    "                tmpind += [tf.gather_nd(\n",
    "                    (batchBeamSeq + tf.cast(batch_size,tf.int64)*beam_path[k]),tmpind[-1])]\n",
    "            actions = tmplst\n",
    "\n",
    "        else:\n",
    "            actions = actions_tmp\n",
    "\n",
    "        if self.args['min_trucks']:\n",
    "            tile_input_pt = tf.tile(input_pnt[:,env.n_nodes-1,:],[beam_width,1])\n",
    "            R = self.reward_func(actions,args['decode_len'],self.args['n_nodes']-1,tile_input_pt)\n",
    "        else:\n",
    "            R = self.reward_func(actions)\n",
    "\n",
    "\n",
    "        ### critic\n",
    "        v = tf.constant(0)\n",
    "        if decode_type=='stochastic':\n",
    "            with tf.compat.v1.variable_scope(\"Critic\"):\n",
    "                with tf.compat.v1.variable_scope(\"Encoder\"):\n",
    "                    # init states\n",
    "                    initial_state = tf.zeros([args['rnn_layers'], 2, batch_size, args['hidden_dim']])\n",
    "                    l = tf.unstack(initial_state, axis=0)\n",
    "                    rnn_tuple_state = tuple([tf.compat.v1.nn.rnn_cell.LSTMStateTuple(l[idx][0],l[idx][1]) # index + corresponds to coord\n",
    "                              for idx in range(args['rnn_layers'])])\n",
    "\n",
    "                    hy = rnn_tuple_state[0][1]\n",
    "\n",
    "                with tf.compat.v1.variable_scope(\"Process\"):\n",
    "                    for i in range(args['n_process_blocks']):\n",
    "\n",
    "                        process = self.clAttentionCritic(args['hidden_dim'],_name=\"P\"+str(i))\n",
    "                        e,logit = process(hy, encoder_emb_inp, env)\n",
    "\n",
    "                        prob = tf.nn.softmax(logit)\n",
    "                        # hy : [batch_size x 1 x sourceL] * [batch_size  x sourceL x hidden_dim]  ->\n",
    "                        #[batch_size x h_dim ]\n",
    "                        hy = tf.squeeze(tf.matmul(tf.expand_dims(prob,1), e ) ,1)\n",
    "\n",
    "                with tf.compat.v1.variable_scope(\"Linear\"):\n",
    "                    v = tf.squeeze(tf.compat.v1.layers.dense(tf.compat.v1.layers.dense(hy,args['hidden_dim']\\\n",
    "                                                               ,tf.nn.relu,name='L1'),1,name='L2'),1)\n",
    "\n",
    "\n",
    "        return (R, v, logprobs, actions, idxs, env.input_pnt , probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3916f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent( RLAgent ):\n",
    "    def build_train_step(self):\n",
    "        '''\n",
    "        This function returns a train_step op, in which by running it we proceed one training step.\n",
    "        '''\n",
    "        args = self.args\n",
    "\n",
    "        R, v, logprobs, actions, idxs , batch , probs= self.train_summary\n",
    "\n",
    "        v_nograd = tf.stop_gradient(v)\n",
    "        R = tf.stop_gradient(R)\n",
    "\n",
    "        # losses\n",
    "        actor_loss = tf.reduce_mean(input_tensor=tf.multiply((R-v_nograd),tf.add_n(logprobs)),axis=0)     # compute mean over the zero axis\n",
    "        critic_loss = tf.compat.v1.losses.mean_squared_error(R,v)\n",
    "\n",
    "        # optimizers\n",
    "        actor_optim = tf.compat.v1.train.AdamOptimizer(args['actor_net_lr'])\n",
    "        critic_optim = tf.compat.v1.train.AdamOptimizer(args['critic_net_lr'])\n",
    "\n",
    "        # compute gradients\n",
    "        actor_gra_and_var = actor_optim.compute_gradients(actor_loss,\\\n",
    "                                tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Actor'))\n",
    "        critic_gra_and_var = critic_optim.compute_gradients(critic_loss,\\\n",
    "                                tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Critic'))\n",
    "\n",
    "        # clip gradients\n",
    "        clip_actor_gra_and_var = [(tf.clip_by_norm(grad, args['max_grad_norm']), var) \\\n",
    "                                  for grad, var in actor_gra_and_var]\n",
    "\n",
    "        clip_critic_gra_and_var = [(tf.clip_by_norm(grad, args['max_grad_norm']), var) \\\n",
    "                                  for grad, var in critic_gra_and_var]\n",
    "\n",
    "        # apply gradients\n",
    "        actor_train_step = actor_optim.apply_gradients(clip_actor_gra_and_var)\n",
    "        critic_train_step = critic_optim.apply_gradients(clip_critic_gra_and_var)\n",
    "\n",
    "        train_step = [actor_train_step,\n",
    "                          critic_train_step ,\n",
    "                          actor_loss,\n",
    "                          critic_loss,\n",
    "                          actor_gra_and_var,\n",
    "                          critic_gra_and_var,\n",
    "                          R,\n",
    "                          v,\n",
    "                          logprobs,\n",
    "                          probs,\n",
    "                          actions,\n",
    "                          idxs]\n",
    "        return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ae4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLAgent( RLAgent ):\n",
    "    def Initialize(self,sess):\n",
    "        self.sess = sess\n",
    "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        self.load_model()\n",
    "\n",
    "    def load_model(self):\n",
    "        latest_ckpt = tf.train.latest_checkpoint(self.args['load_path'])\n",
    "        if latest_ckpt is not None:\n",
    "            print(\"have load model\")\n",
    "            self.saver.restore(self.sess, latest_ckpt)\n",
    "\n",
    "\n",
    "    def evaluate_single(self,eval_type='greedy'):\n",
    "        start_time = time.time()\n",
    "        avg_reward = []\n",
    "        all_output = []\n",
    "\n",
    "        if eval_type == 'greedy':\n",
    "            summary = self.val_summary_greedy\n",
    "        elif eval_type == 'beam_search':\n",
    "            summary = self.val_summary_beam\n",
    "        self.dataGen.reset()\n",
    "        for step in range(self.dataGen.n_problems):\n",
    "\n",
    "            data = self.dataGen.get_test_next()\n",
    "            input_concat = np.concatenate(data)\n",
    "            norm_by_feature = np.reshape(np.transpose(input_concat),(self.args['input_dim'],-1))\n",
    "            norm_by_feature = normalize(norm_by_feature, axis=1)\n",
    "            data_norm = np.reshape(np.transpose(norm_by_feature),(data.shape[0],data.shape[1],data.shape[2]))\n",
    "\n",
    "            if self.args['embedding_graph'] == 0:\n",
    "                dict_to_feed = {self.env.input_data:data,\n",
    "                                self.env.input_data_norm:data_norm,\n",
    "                                self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                                self.decodeStep.dropout:0.0}\n",
    "            elif self.args['embedding_graph'] == 1:\n",
    "                dict_to_feed = {self.env.input_data:data,\n",
    "                                self.env.input_data_norm:data_norm,\n",
    "                                self.env.embeded_data:self.embedder_model(data),\n",
    "                                self.decodeStep.dropout:0.0}\n",
    "            else:\n",
    "                dict_to_feed = {self.env.input_data:data,\n",
    "                                self.env.input_data_norm:data_norm,\n",
    "                                self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                                self.embedder_model.drop_out: 1.0,\n",
    "                                self.decodeStep.dropout:0.0}\n",
    "\n",
    "            R, v, logprobs, actions,idxs, batch, _= self.sess.run(summary,\n",
    "                                         feed_dict=dict_to_feed)\n",
    "            if eval_type=='greedy':\n",
    "                avg_reward.append(R)\n",
    "                R_ind0 = 0\n",
    "            elif eval_type=='beam_search':\n",
    "                # R : [batch_size x beam_width]\n",
    "                R = np.concatenate(np.split(np.expand_dims(R,1) ,self.args['beam_width'], axis=0),1 )\n",
    "                R_val = np.amin(R,1, keepdims = False)\n",
    "                R_ind0 = np.argmin(R,1)[0]\n",
    "                avg_reward.append(R_val)\n",
    "\n",
    "            # print decode in file data\n",
    "            example_output = [list(batch[0, self.env.n_nodes-1, :])] # we begin by the depot\n",
    "            for idx, action in enumerate(actions):\n",
    "                example_output.append(list(action[R_ind0*np.shape(batch)[0]]))\n",
    "            all_output.append(example_output)\n",
    "\n",
    "\n",
    "            # sample decode\n",
    "            if step % int(self.args['log_interval']) == 0:\n",
    "                example_output = []\n",
    "                example_input = []\n",
    "                for i in range(self.env.n_nodes):\n",
    "                    example_input.append(list(batch[0, i, :]))\n",
    "                for idx, action in enumerate(actions):\n",
    "                    example_output.append(list(action[R_ind0*np.shape(batch)[0]]))\n",
    "                self.prt.print_out('\\n\\nVal-Step of {}: {}'.format(eval_type,step))\n",
    "                self.prt.print_out('\\nExample test input: {}'.format(example_input))\n",
    "                self.prt.print_out('\\nExample test output: {}'.format(example_output))\n",
    "                self.prt.print_out('\\nExample test reward: {} - best: {}'.format(R[0],R_ind0))\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "\n",
    "        # Finished going through the iterator dataset.\n",
    "        self.prt.print_out('\\nValidation overall avg_reward: {}'.format(np.mean(avg_reward)) )\n",
    "        self.prt.print_out('Validation overall reward std: {}'.format(np.sqrt(np.var(avg_reward))) )\n",
    "\n",
    "        self.prt.print_out(\"Finished evaluation with %d steps in %s.\" % (step\\\n",
    "                           ,time.strftime(\"%H:%M:%S\", time.gmtime(end_time))))\n",
    "\n",
    "        # Ouputting the results\n",
    "        self._output_results(all_output,eval_type)\n",
    "\n",
    "\n",
    "    def _output_results(self,all_ouput,eval_type):\n",
    "        \"\"\"\n",
    "        Output the deconding results obtained after a single inference\n",
    "        :param all_ouput: list of routes, in order\n",
    "        :param eval_type: the type (greedy or beam_search)\n",
    "        \"\"\"\n",
    "        # create directory\n",
    "        dir_name = os.path.join(self.args['log_dir'],'results')\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "\n",
    "        task = self.args['task_name']\n",
    "        # build task name and datafiles\n",
    "        if self.args['ups']:\n",
    "            task_name = '{}-ups-size-{}-len-{}-results-{}.txt'.format(task,self.args['test_size'], self.env.n_nodes,eval_type)\n",
    "        else:\n",
    "            task_name = '{}-size-{}-len-{}-results-{}.txt'.format(task,self.args['test_size'], self.env.n_nodes,eval_type)\n",
    "        fname = os.path.join(self.args['log_dir'],'results', task_name)\n",
    "\n",
    "        input_file =open(fname, 'w')\n",
    "        for output in all_ouput:\n",
    "            depot_x = output[0][0]\n",
    "            depot_y = output[0][1]\n",
    "\n",
    "            nb_stop = 0\n",
    "            for node in output:\n",
    "                if task == 'vrp':\n",
    "                    input_file.write(str(node[0]) + \" \" + str(node[1]) + \" \")\n",
    "                elif task =='vrptw':\n",
    "                    input_file.write(str(node[0]) + \" \" + str(node[1]) + \" \" + str(node[2]) + \" \" + str(node[3]) + \" \")\n",
    "                else:\n",
    "                    assert False\n",
    "                # check if depot or stop\n",
    "                if abs(depot_x - node[0]) >= 0.001 or abs(depot_y - node[1]) >= 0.001:\n",
    "                    nb_stop +=1\n",
    "\n",
    "                if nb_stop == self.env.n_nodes -1:\n",
    "                    # we have found all the stops so write depot again and break\n",
    "                    if task == 'vrp':\n",
    "                        input_file.write(str(depot_x) + \" \" + str(depot_y))\n",
    "                    elif task =='vrptw':\n",
    "                        depot_b_tw = output[0][2]\n",
    "                        depot_e_tw = output[0][3]\n",
    "                        input_file.write(str(depot_x) + \" \" + str(depot_y) + \" \" + str(depot_b_tw) + \" \" + str(depot_e_tw))\n",
    "                    break\n",
    "            input_file.write(\"\\n\")\n",
    "        input_file.close()\n",
    "\n",
    "        # copy the input file\n",
    "        if self.args['ups']:\n",
    "            copy_name = '{}-ups-size-{}-len-{}-test.txt'.format(task,self.args['test_size'], self.env.n_nodes)\n",
    "        else:\n",
    "            copy_name = '{}-size-{}-len-{}-test.txt'.format(task,self.args['test_size'], self.env.n_nodes)\n",
    "        old_loc = os.path.join(self.args['data_dir'], copy_name)\n",
    "        new_loc = os.path.join(self.args['log_dir'],'results', copy_name)\n",
    "        copyfile(old_loc,new_loc)\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate_batch(self,eval_type='greedy'):\n",
    "        self.env.reset()\n",
    "        if eval_type == 'greedy':\n",
    "            summary = self.val_summary_greedy\n",
    "            beam_width = 1\n",
    "        elif eval_type == 'beam_search':\n",
    "            summary = self.val_summary_beam\n",
    "            beam_width = self.args['beam_width']\n",
    "\n",
    "\n",
    "        data = self.dataGen.get_test_all()\n",
    "        input_concat = np.concatenate(data)\n",
    "        norm_by_feature = np.reshape(np.transpose(input_concat),(self.args['input_dim'],-1))\n",
    "        norm_by_feature = normalize(norm_by_feature, axis=1)\n",
    "        data_norm = np.reshape(np.transpose(norm_by_feature),(data.shape[0],data.shape[1],data.shape[2]))\n",
    "\n",
    "        if self.args['embedding_graph'] == 0:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                            self.decodeStep.dropout:0.0}\n",
    "        elif self.args['embedding_graph'] == 1:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data:self.embedder_model(data),\n",
    "                            self.decodeStep.dropout:0.0}\n",
    "        else:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                            self.embedder_model.drop_out: 1.0,\n",
    "                            self.decodeStep.dropout:0.0}\n",
    "\n",
    "        start_time = time.time()\n",
    "        R, v, logprobs, actions,idxs, batch, _= self.sess.run(summary,\n",
    "                                     feed_dict=dict_to_feed)\n",
    "\n",
    "        R = np.concatenate(np.split(np.expand_dims(R,1) ,beam_width, axis=0),1 )\n",
    "        R = np.amin(R,1, keepdims = False)\n",
    "\n",
    "        end_time = time.time() - start_time\n",
    "        self.prt.print_out('Average of {} in batch-mode: {} -- std {} -- time {} s'.format(eval_type,\\\n",
    "            np.mean(R),np.sqrt(np.var(R)),end_time))\n",
    "        self.out_avg_resul.write(eval_type + '_' + str(np.mean(R)) + '\\n')\n",
    "\n",
    "    def inference(self, infer_type='batch'):\n",
    "        if infer_type == 'batch':\n",
    "            self.evaluate_batch('greedy')\n",
    "            self.evaluate_batch('beam_search')\n",
    "        elif infer_type == 'single':\n",
    "            self.evaluate_single('greedy')\n",
    "            self.evaluate_single('beam_search')\n",
    "        self.prt.print_out(\"##################################################################\")\n",
    "\n",
    "\n",
    "    def run_train_step(self):\n",
    "        data = self.dataGen.get_train_next()\n",
    "        input_concat = np.concatenate(data)\n",
    "        norm_by_feature = np.reshape(np.transpose(input_concat),(self.args['input_dim'],-1))\n",
    "        norm_by_feature = normalize(norm_by_feature, axis=1)\n",
    "        data_norm = np.reshape(np.transpose(norm_by_feature),(data.shape[0],data.shape[1],data.shape[2]))\n",
    "\n",
    "        if self.args['embedding_graph'] == 0:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                            self.decodeStep.dropout:self.args['dropout']}\n",
    "        elif self.args['embedding_graph'] == 1:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data:self.embedder_model(data),\n",
    "                            self.decodeStep.dropout:self.args['dropout']}\n",
    "        else:\n",
    "            dict_to_feed = {self.env.input_data:data,\n",
    "                            self.env.input_data_norm:data_norm,\n",
    "                            self.env.embeded_data: np.zeros(shape=(self.args['batch_size'],self.args['n_nodes'],self.args['embedding_dim'])),\n",
    "                            self.embedder_model.drop_out: 0.8,\n",
    "                            self.decodeStep.dropout:self.args['dropout']}\n",
    "\n",
    "        train_results = self.sess.run(self.train_step,\n",
    "                                 feed_dict=dict_to_feed)\n",
    "        return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(object):\n",
    "    '''\n",
    "    This class is the base class for embedding the input graph.\n",
    "    '''\n",
    "    def __init__(self,emb_type, embedding_dim):\n",
    "        self.emb_type = emb_type\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.total_time = 0\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # returns the embeded tensor. Should be implemented in child classes\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a987c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEmbedding(Embedding):\n",
    "    '''\n",
    "    This class implements linear embedding. It is only a mapping \n",
    "    to a higher dimensional space.\n",
    "    '''\n",
    "    def __init__(self,embedding_dim,_scope=''):\n",
    "        '''\n",
    "        Input: \n",
    "            embedding_dim: embedding dimension\n",
    "        '''\n",
    "\n",
    "        super(LinearEmbedding,self).__init__('linear',embedding_dim)\n",
    "        self.project_emb = tf.compat.v1.layers.Conv1D(embedding_dim,1,\n",
    "            _scope=_scope+'Embedding/conv1d')\n",
    "\n",
    "    def __call__(self,input_pnt):\n",
    "        # emb_inp_pnt: [batch_size, max_time, embedding_dim]\n",
    "        time_init = time.time()\n",
    "        emb_inp_pnt = self.project_emb(input_pnt)\n",
    "        # emb_inp_pnt = tf.Print(emb_inp_pnt,[emb_inp_pnt])\n",
    "        self.total_time += time.time() - time_init\n",
    "        return emb_inp_pnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52554ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEmbedding(Embedding):\n",
    "    \"\"\"\n",
    "    This class implement a graph embedding. The specificity is that it has already been optimized on\n",
    "    another task. Implementation of transfer learning.\n",
    "    \"\"\"\n",
    "    def __init__(self,args,data_test):\n",
    "        assert args['embedding_dim'] == 30, args['embedding_dim']\n",
    "        super(GraphEmbedding, self).__init__('graph',embedding_dim=args['embedding_dim'])\n",
    "\n",
    "        self.n_nodes = args['n_nodes']\n",
    "        self.embedding_dim =  args['embedding_dim']\n",
    "        model_path = 'shared/graph_embedding/model_storage/' + args['task'] + '_model.pickle'\n",
    "        result_dir = args['log_dir'] + '/embedding/'\n",
    "        os.makedirs(result_dir)\n",
    "        self.graph_model = self.restore(model_path, result_dir)\n",
    "        self.graph_model.params['max_nodes_in_batch'] = args['test_size'] * self.n_nodes + 10 # We can process larger batches if we don't do training\n",
    "        self.embedded_data = self(data_test)\n",
    "\n",
    "\n",
    "    def __call__(self, input_data):\n",
    "        \"\"\"\n",
    "        :param input_data: the input data as given by the env i.e. [batch_size x max_time x dim_task]\n",
    "        :return: an embedding corresponding to the final node represenatation obtained via transfer learning.\n",
    "        \"\"\"\n",
    "        time_init = time.time()\n",
    "        embedded_data = self.graph_model.test(input_data)\n",
    "        embedded_data = np.reshape(embedded_data,(-1,self.n_nodes,self.embedding_dim))\n",
    "        self.total_time += time.time() - time_init\n",
    "\n",
    "        return embedded_data\n",
    "\n",
    "    @staticmethod\n",
    "    def restore(saved_model_path: str, result_dir: str, run_id: str = None):\n",
    "        print(\"Loading model from file %s.\" % saved_model_path)\n",
    "        with open(saved_model_path, 'rb') as in_file:\n",
    "            data_to_load = pickle.load(in_file)\n",
    "\n",
    "        # model_cls, _ = name_to_model_class(data_to_load['model_class']({}))   # before...\n",
    "        model_cls = GNN_FiLM_Model\n",
    "        task_cls, additional_task_params = Nb_Vehicles_Task, {\"data_kind\":'transfer_learning'}\n",
    "\n",
    "        if run_id is None:\n",
    "            run_id = \"_\".join([task_cls.name(), model_cls.name(data_to_load['model_params']), time.strftime(\"%Y-%m-%d-%H-%M-%S\"), str(os.getpid())])\n",
    "\n",
    "        task = task_cls(data_to_load['task_params'])\n",
    "        task.restore_from_metadata(data_to_load['task_metadata'])\n",
    "\n",
    "        model = model_cls(data_to_load['model_params'], task, run_id, result_dir)\n",
    "        model.load_weights(data_to_load['weights'])\n",
    "\n",
    "        model.log_line(\"Loaded model from snapshot %s.\" % saved_model_path)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    args, prt = ParseParams()\n",
    "    data_Gen = DataGenerator(args)\n",
    "    # print(data_Gen.test_data)\n",
    "    print(data_Gen.test_data.shape)\n",
    "\n",
    "    graph_embedding = GraphEmbedding(args,data_Gen.test_data)\n",
    "    data = data_Gen.get_train_next()\n",
    "    graph_embedding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228a376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "def load_task_specific_components(task,ups):\n",
    "    '''\n",
    "    This function load task-specific libraries\n",
    "    '''\n",
    "    if task == 'vrp':\n",
    "        if ups:\n",
    "            from UPS.vrp_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrp_ups_attention import AttentionVRP_UPS_Actor, AttentionVRP_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRP_UPS_Actor\n",
    "            AttentionCritic = AttentionVRP_UPS_Critic\n",
    "\n",
    "        else:\n",
    "            from VRP.vrp_utils import DataGenerator,Env,reward_func\n",
    "            from VRP.vrp_attention import AttentionVRPActor,AttentionVRPCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPActor\n",
    "            AttentionCritic = AttentionVRPCritic\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        if ups:\n",
    "            from UPS.vrptw_ups_utils import DataGenerator,Env,reward_func\n",
    "            from UPS.vrptw_ups_attention import AttentionVRPTW_UPS_Actor, AttentionVRPTW_UPS_Critic\n",
    "\n",
    "            AttentionActor = AttentionVRPTW_UPS_Actor\n",
    "            AttentionCritic = AttentionVRPTW_UPS_Critic\n",
    "        else:\n",
    "            from VRPTW.vrptw_utils import DataGenerator,Env,reward_func\n",
    "            from VRPTW.vrptw_attention import AttentionVRPTWActor, AttentionVRPTWCritic\n",
    "\n",
    "            AttentionActor = AttentionVRPTWActor\n",
    "            AttentionCritic = AttentionVRPTWCritic\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')\n",
    "\n",
    "    return DataGenerator, Env, reward_func, AttentionActor, AttentionCritic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04130236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_task_specific_eval(task):\n",
    "    \"\"\"\n",
    "    Load taks specific, dependign of tw or not\n",
    "    \"\"\"\n",
    "    if task == 'vrp':\n",
    "        from evaluation.eval_VRP import eval_google_or,eval_Clarke_Wright\n",
    "\n",
    "        return [(eval_google_or.EvalGoogleOR,'or_tools'), (eval_Clarke_Wright.EvalClarkeWright,'Clarke_Wright')]\n",
    "\n",
    "    elif task == 'vrptw':\n",
    "        from evaluation.eval_VRPTW import eval_tw_google_or,eval_I1_heuristics\n",
    "\n",
    "        return [(eval_tw_google_or.EvalTWGoogleOR,'or_tools_tw'),(eval_I1_heuristics.EvalI1Heuristics,'I1_heuristic')]\n",
    "\n",
    "    else:\n",
    "        raise Exception('Task is not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cda45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args, prt):\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "    \n",
    "    # load task specific classes\n",
    "    DataGenerator, Env, reward_func, AttentionActor, AttentionCritic = \\\n",
    "        load_task_specific_components(args['task_name'],args['ups'])\n",
    "\n",
    "    dataGen = DataGenerator(args)\n",
    "    dataGen.reset()\n",
    "    env = Env(args)\n",
    "    # create an RL agent\n",
    "    agent = RLAgent(args,\n",
    "                    prt,\n",
    "                    env,\n",
    "                    dataGen,\n",
    "                    reward_func,\n",
    "                    AttentionActor,\n",
    "                    AttentionCritic,\n",
    "                    is_train=args['is_train'])\n",
    "    agent.Initialize(sess)\n",
    "\n",
    "    # train or evaluate\n",
    "    prev_actor_loss, prev_critic_loss = float('Inf'), float('Inf')\n",
    "    actor_eps, critic_eps = 1e-2, 1e-2\n",
    "    start_time = time.time()\n",
    "    convergence_counter = 0\n",
    "    al_file = open(args['log_dir']+\"/actorLoss.txt\", \"w\")\n",
    "    cl_file = open(args['log_dir']+\"/criticLoss.txt\", \"w\")\n",
    "    r_file = open(args['log_dir']+\"/reward.txt\", \"w\")\n",
    "\n",
    "    if args['is_train']:\n",
    "        prt.print_out('Training started ...')\n",
    "        train_time_beg = time.time()\n",
    "        for step in range(args['n_train']):\n",
    "            summary = agent.run_train_step()\n",
    "            _, _ , actor_loss_val, critic_loss_val, actor_gra_and_var_val, critic_gra_and_var_val,\\\n",
    "                R_val, v_val, logprobs_val,probs_val, actions_val, idxs_val= summary\n",
    "\n",
    "            curr_actor_loss = np.mean(actor_loss_val)\n",
    "            curr_critic_loss = np.mean(critic_loss_val)\n",
    "            al_file.write( str(actor_loss_val) + '\\n')\n",
    "            cl_file.write(str(critic_loss_val) + '\\n')\n",
    "            r_file.write(str(np.mean(R_val)) + '\\n')\n",
    "\n",
    "            if abs(prev_actor_loss - curr_actor_loss) < actor_eps \\\n",
    "                and abs(prev_critic_loss - curr_critic_loss) < critic_eps:\n",
    "                convergence_counter += 1\n",
    "            else:\n",
    "                convergence_counter = 0\n",
    "            if convergence_counter == 10:\n",
    "                prt.print_out('Converged at step {}'\\\n",
    "                      .format(step))\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss,curr_critic_loss))\n",
    "                break\n",
    "\n",
    "            if step%args['save_interval'] == 0:\n",
    "                agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "            if step%args['log_interval'] == 0:\n",
    "                train_time_end = time.time()-train_time_beg\n",
    "                prt.print_out('Train Step: {} -- Time: {} -- Embedding Time {} -- Train reward: {} -- Value: {}'\\\n",
    "                      .format(step,time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        train_time_end)),time.strftime(\"%H:%M:%S\", time.gmtime(\\\n",
    "                        agent.embedder_model.total_time)),np.mean(R_val),np.mean(v_val)))\n",
    "                prt.print_out('    actor loss: {} -- critic loss: {}'\\\n",
    "                      .format(curr_actor_loss, curr_critic_loss))\n",
    "\n",
    "                train_time_beg = time.time()\n",
    "                agent.embedder_model.total_time = 0\n",
    "            if step%args['test_interval'] == 0:\n",
    "                agent.inference(args['infer_type'])\n",
    "            prev_actor_loss = curr_actor_loss\n",
    "            prev_critic_loss = curr_critic_loss\n",
    "\n",
    "        # Save the model at the end of the training\n",
    "        agent.saver.save(sess,args['model_dir']+'/model.ckpt', global_step=step)\n",
    "\n",
    "    else: # inference\n",
    "        prt.print_out('Evaluation started ...')\n",
    "        agent.inference(args['infer_type'])\n",
    "\n",
    "        all_evaluator = load_task_specific_eval(args['task_name'])\n",
    "\n",
    "        # perform the evaluation\n",
    "        list_eval = ['beam_search'] #['greedy','beam_search']\n",
    "        for eval_tuple in all_evaluator:\n",
    "            list_eval.append(eval_tuple[1])\n",
    "\n",
    "            object_eval = eval_tuple[0](args,env,prt,args['min_trucks'])\n",
    "            object_eval.perform_routing()\n",
    "        #\n",
    "        benchmark_object = benchmark.Benchmark(args,env,prt)\n",
    "        # list_eval.remove('Clarke_Wright')\n",
    "        # #list_eval.remove('I1_heuristic')\n",
    "        benchmark_object.perform_benchmark(list_eval=list_eval)\n",
    "\n",
    "    prt.print_out('Total time is {}'.format(time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time))))\n",
    "    al_file.close()\n",
    "    cl_file.close()\n",
    "    r_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56ab94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #test()\n",
    "    #assert False\n",
    "    args, prt = ParseParams()\n",
    "    args['is_train'] = True\n",
    "    # args['infer_type'] = 'single'\n",
    "    args['test_size'] = 1000\n",
    "   #  args['log_dir'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp20-2019-12-05_09-28-11/\"\n",
    "    # args['load_path'] = \"/Users/jpoullet/Documents/MIT/Thesis/ML6867_project/VRP-RL/logs/vrp50-NbTruck/model/\"\n",
    "\n",
    "    # args['data_dir'] = \"drive/My Drive/VRP-RL/data\"\n",
    "    # args['log_dir'] = \"drive/My Drive/VRP-RL/logs\"\n",
    "    # args['log_dir'] = \"{}/{}-{}\".format(args['log_dir'],args['task'], utils.get_time())\n",
    "    # print(args['log_dir'])\n",
    "    # args['model_dir'] = os.path.join(args['log_dir'],'model')\n",
    "    #\n",
    "    # args['load_path'] = \"drive/My Drive/VRP-RL/logs/vrptw50-2019-11-25_01-28-09/model/\"\n",
    "    # print(args['model_dir'])\n",
    "    # # file to write the stdout\n",
    "    # try:\n",
    "    #     os.makedirs(args['log_dir'])\n",
    "    #     os.makedirs(args['model_dir'])\n",
    "    # except:\n",
    "    #     pass\n",
    "    #\n",
    "    # # create a print handler\n",
    "    # out_file = open(os.path.join(args['log_dir'], 'results.txt'),'w+')\n",
    "    # prt = utils.printOut(out_file,args['stdout_print'])\n",
    "\n",
    "    # Random\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    random_seed = args['random_seed']\n",
    "    if random_seed is not None and random_seed > 0:\n",
    "        prt.print_out(\"# Set random seed to %d\" % random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "        tf.random.set_seed(random_seed)\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    main(args, prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847440a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca381e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7929df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
